{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import itertools\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# import warnings\n",
    "# warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the data\n",
    "\n",
    "Note about the data: The dataset is rather large, and very skewed toward valid transactions. To balance it a bit better, we sample and only keep around 5% of the valid transactions (the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data is imbalanced, with 14613 samples in total but only 492 cases of fraud\n"
     ]
    }
   ],
   "source": [
    "with open('creditcard.csv', newline='') as f:\n",
    "    reader = csv.reader(f, delimiter=',')\n",
    "    csv_data = list(reader)[1:]\n",
    "    \n",
    "csv_data = [row for row in csv_data if int(row[-1]) == 1 or random.random() < .05]\n",
    "\n",
    "# Format: Time, V1, ..., V28, Amount, Class\n",
    "data = np.array([[float(x) for x in row[1:-1]] for row in csv_data])\n",
    "times = np.array([float(row[0]) for row in csv_data])\n",
    "labels = np.array([int(row[-1]) for row in csv_data])\n",
    "print('The data is imbalanced, with {} samples in total but only {} cases of fraud'.format(len(labels), sum(labels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.36138071e-01  1.08747932e-01 -2.31636452e-01  1.43066709e-01\n",
      " -8.71082980e-02 -5.13922332e-02 -1.64526465e-01  7.89883117e-03\n",
      " -9.76343425e-02 -1.88949167e-01  1.24586302e-01 -1.87390859e-01\n",
      " -1.01443419e-02 -2.29775306e-01  7.81853052e-03 -1.31768137e-01\n",
      " -2.22835738e-01 -8.47656214e-02  2.94615613e-02  1.32879422e-02\n",
      "  3.18184249e-02  1.20779615e-02 -5.21694121e-03 -6.69735803e-03\n",
      " -3.74077645e-03  1.01309416e-03  5.11590009e-03 -1.09001717e-03\n",
      "  9.11537166e+01]\n",
      "[5.84373454e+00 3.85842725e+00 5.38963903e+00 2.86785646e+00\n",
      " 3.09604938e+00 1.88607838e+00 4.11254513e+00 2.86731019e+00\n",
      " 1.53335185e+00 2.90503745e+00 1.66953850e+00 2.84290350e+00\n",
      " 9.88577657e-01 2.95215138e+00 8.32541491e-01 1.75163967e+00\n",
      " 3.63238363e+00 1.11950579e+00 7.37049834e-01 7.38136345e-01\n",
      " 1.08624144e+00 6.02125068e-01 4.17537170e-01 3.67978125e-01\n",
      " 2.84038369e-01 2.25896809e-01 2.19285145e-01 8.80268571e-02\n",
      " 8.66798281e+04]\n",
      "The PCA features have mean 0 but different variances\n",
      "The transaction amount is not scaled. We should scale it so it does not affect the SVM too much\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(data, axis=0))\n",
    "print(np.var(data, axis=0))\n",
    "print('The PCA features have mean 0 but different variances')\n",
    "print('The transaction amount is not scaled. We should scale it so it does not affect the SVM too much')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 5.89338261e-16  4.03293471e-16  9.97119007e-16 -5.79879370e-16\n",
      " -4.76211450e-16 -1.81428357e-17 -1.57786829e-16 -2.39646119e-16\n",
      "  3.56482410e-16  1.30526990e-15  1.23003564e-15  5.80259245e-16\n",
      " -2.09903796e-16  6.21574463e-16 -3.82640610e-16 -4.71045148e-19\n",
      " -8.53190022e-17  4.85434818e-16 -6.33631700e-18  2.04657721e-17\n",
      " -1.95960480e-16 -3.43255158e-17  1.72477550e-17 -2.96302593e-18\n",
      " -3.45321679e-16  7.94698750e-17 -1.42871032e-17  1.57553206e-17\n",
      "  6.48917684e-15]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "data_sc = scaler.fit_transform(data)\n",
    "print(np.mean(data_sc, axis=0))\n",
    "print(np.var(data_sc, axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preliminary plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.06937359  0.24749113  1.23742903 -0.93573151 -1.16942246  0.15833178\n",
      "  1.110692    1.14736893  1.15693907]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the first two principal components\n",
    "data_fraud = data[np.where(labels == 1)]\n",
    "data_valid = data[np.where(labels == 0)]\n",
    "plt.scatter(data_valid[:, 0], data_valid[:, -1], c='b')\n",
    "plt.scatter(data_fraud[:, 0], data_fraud[:, -1], c='r')\n",
    "print(data_valid[1:10, 0])\n",
    "plt.ylim((0, 10000))\n",
    "plt.legend(['valid', 'fraud'])\n",
    "plt.xlabel('First PCA feature')\n",
    "plt.ylabel('Transaction amount')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraud_indices = np.where(labels == 1)[0]\n",
    "np.random.shuffle(fraud_indices)\n",
    "fraud_splits = np.array_split(fraud_indices, 5)\n",
    "\n",
    "valid_indices = np.where(labels == 0)[0]\n",
    "np.random.shuffle(valid_indices)\n",
    "valid_splits = np.array_split(valid_indices, 5)\n",
    "\n",
    "folds = [np.concatenate((fraud_sp, valid_sp)) for fraud_sp, valid_sp in zip(fraud_splits, valid_splits)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_binary_SVM(data, scale=False, kernel=None, class_weight=None):\n",
    "    confusion_mat = np.zeros((2, 2))\n",
    "    for i in range(5):\n",
    "        if kernel is None:\n",
    "            if class_weight is None:\n",
    "                svm = LinearSVC(fit_intercept=False, dual=False)\n",
    "            else:\n",
    "                svm = LinearSVC(fit_intercept=False, dual=False, class_weight=class_weight)\n",
    "        else:\n",
    "            if class_weight is None:\n",
    "                svm = SVC(kernel=kernel, gamma='auto')\n",
    "            else:\n",
    "                svm = SVC(kernel=kernel, gamma='auto', class_weight=class_weight)\n",
    "        \n",
    "        train_data = np.delete(data, folds[i], axis=0)\n",
    "        test_data = data[folds[i]]\n",
    "        if scale:\n",
    "            scaler = StandardScaler()\n",
    "            train_data = scaler.fit_transform(train_data)\n",
    "            test_data = scaler.transform(test_data)\n",
    "\n",
    "        svm.fit(train_data, np.delete(labels, folds[i]))\n",
    "        pred = svm.predict(test_data)\n",
    "\n",
    "        conf_mat = confusion_matrix(labels[folds[i]], pred)\n",
    "        print('Fold', i)\n",
    "        print(conf_mat)\n",
    "\n",
    "        confusion_mat += conf_mat\n",
    "\n",
    "    confusion_mat /= 5\n",
    "    print('Final Confusion Matrix')\n",
    "    print(confusion_mat)\n",
    "    print('False negatives (valid):', confusion_mat[0, 1] / sum(confusion_mat[0, :]))\n",
    "    print('False positives (fraud):', confusion_mat[1, 0] / sum(confusion_mat[1,:]))\n",
    "    return confusion_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear SVM -- Without scaling or class weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0\n",
      "[[2816    9]\n",
      " [  20   79]]\n",
      "Fold 1\n",
      "[[2810   14]\n",
      " [  19   80]]\n",
      "Fold 2\n",
      "[[2815    9]\n",
      " [  24   74]]\n",
      "Fold 3\n",
      "[[2815    9]\n",
      " [  23   75]]\n",
      "Fold 4\n",
      "[[2816    8]\n",
      " [  19   79]]\n",
      "Final Confusion Matrix\n",
      "[[2814.4    9.8]\n",
      " [  21.    77.4]]\n",
      "False negatives (valid): 0.0034700092061468735\n",
      "False positives (fraud): 0.21341463414634146\n"
     ]
    }
   ],
   "source": [
    "train_binary_SVM(data);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear SVM with Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0\n",
      "[[2816    9]\n",
      " [  13   86]]\n",
      "Fold 1\n",
      "[[2820    4]\n",
      " [  16   83]]\n",
      "Fold 2\n",
      "[[2816    8]\n",
      " [  20   78]]\n",
      "Fold 3\n",
      "[[2817    7]\n",
      " [  17   81]]\n",
      "Fold 4\n",
      "[[2813   11]\n",
      " [  16   82]]\n",
      "Final Confusion Matrix\n",
      "[[2816.4    7.8]\n",
      " [  16.4   82. ]]\n",
      "False negatives (valid): 0.002761844062035266\n",
      "False positives (fraud): 0.16666666666666663\n"
     ]
    }
   ],
   "source": [
    "train_binary_SVM(data, scale=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear SVM with Scaling and Class Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0\n",
      "[[2673  152]\n",
      " [   5   94]]\n",
      "Fold 1\n",
      "[[2690  134]\n",
      " [   7   92]]\n",
      "Fold 2\n",
      "[[2723  101]\n",
      " [  11   87]]\n",
      "Fold 3\n",
      "[[2691  133]\n",
      " [   8   90]]\n",
      "Fold 4\n",
      "[[2688  136]\n",
      " [   7   91]]\n",
      "Final Confusion Matrix\n",
      "[[2693.   131.2]\n",
      " [   7.6   90.8]]\n",
      "False negatives (valid): 0.046455633453721404\n",
      "False positives (fraud): 0.07723577235772358\n"
     ]
    }
   ],
   "source": [
    "train_binary_SVM(data, scale=True, class_weight='balanced');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kernel SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RBF Kernel with Scaling and Class Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0\n",
      "[[2823    2]\n",
      " [  20   79]]\n",
      "Fold 1\n",
      "[[2821    3]\n",
      " [  21   78]]\n",
      "Fold 2\n",
      "[[2822    2]\n",
      " [  23   75]]\n",
      "Fold 3\n",
      "[[2823    1]\n",
      " [  21   77]]\n",
      "Fold 4\n",
      "[[2823    1]\n",
      " [  18   80]]\n",
      "Final Confusion Matrix\n",
      "[[2.8224e+03 1.8000e+00]\n",
      " [2.0600e+01 7.7800e+01]]\n",
      "False negatives (valid): 0.0006373486297004461\n",
      "False positives (fraud): 0.20934959349593496\n"
     ]
    }
   ],
   "source": [
    "train_binary_SVM(data, scale=True, kernel='rbf');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0\n",
      "[[2818    7]\n",
      " [  44   55]]\n",
      "Fold 1\n",
      "[[2807   17]\n",
      " [  41   58]]\n",
      "Fold 2\n",
      "[[2805   19]\n",
      " [  45   53]]\n",
      "Fold 3\n",
      "[[2817    7]\n",
      " [  53   45]]\n",
      "Fold 4\n",
      "[[2817    7]\n",
      " [  50   48]]\n",
      "Final Confusion Matrix\n",
      "[[2812.8   11.4]\n",
      " [  46.6   51.8]]\n",
      "False negatives (valid): 0.004036541321436158\n",
      "False positives (fraud): 0.4735772357723577\n"
     ]
    }
   ],
   "source": [
    "train_binary_SVM(data, kernel='rbf', class_weight='balanced');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Polynomial Kernel with Scaling and Class Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0\n",
      "[[2822    3]\n",
      " [  14   85]]\n",
      "Fold 1\n",
      "[[2821    3]\n",
      " [  15   84]]\n",
      "Fold 2\n",
      "[[2821    3]\n",
      " [  24   74]]\n",
      "Fold 3\n",
      "[[2818    6]\n",
      " [  21   77]]\n",
      "Fold 4\n",
      "[[2819    5]\n",
      " [  21   77]]\n",
      "Final Confusion Matrix\n",
      "[[2820.2    4. ]\n",
      " [  19.    79.4]]\n",
      "False negatives (valid): 0.0014163302882232137\n",
      "False positives (fraud): 0.19308943089430894\n"
     ]
    }
   ],
   "source": [
    "train_binary_SVM(data, scale=True, kernel='poly');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0\n",
      "[[2807   18]\n",
      " [  10   89]]\n",
      "Fold 1\n",
      "[[2804   20]\n",
      " [  13   86]]\n",
      "Fold 2\n",
      "[[2812   12]\n",
      " [  19   79]]\n",
      "Fold 3\n",
      "[[2801   23]\n",
      " [  18   80]]\n",
      "Fold 4\n",
      "[[2806   18]\n",
      " [  14   84]]\n",
      "Final Confusion Matrix\n",
      "[[2806.    18.2]\n",
      " [  14.8   83.6]]\n",
      "False negatives (valid): 0.006444302811415622\n",
      "False positives (fraud): 0.15040650406504066\n"
     ]
    }
   ],
   "source": [
    "train_binary_SVM(data, scale=True, kernel='poly', class_weight='balanced');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_logistic_regression(data, class_weight = None, C=1.0):\n",
    "    err = 0\n",
    "    err_valid = 0\n",
    "    err_fraud = 0\n",
    "    confusion_mat = np.zeros((2, 2))\n",
    "    AU = 0\n",
    "    for i in range(5):\n",
    "        model = LogisticRegression(class_weight=class_weight, C=C)\n",
    "        \n",
    "        model.fit(np.delete(data, folds[i], axis=0), np.delete(labels, folds[i]))\n",
    "        pred = model.predict(data[folds[i]])\n",
    "        pred1 = model.predict_proba(data[folds[i]])[:,1]\n",
    "        #err_fold = np.sum((pred - labels[folds[i]])**2) / len(folds[i])\n",
    "        #pred_valid = model.predict(data[valid_splits[i]])\n",
    "        #err_valid_fold = np.sum((pred_valid - labels[valid_splits[i]])**2) / len(valid_splits[i])\n",
    "        #pred_fraud = model.predict(data[fraud_splits[i]])\n",
    "        #err_fraud_fold = np.sum((pred_fraud - labels[fraud_splits[i]])**2) / len(fraud_splits[i])\n",
    "        #print('Fold', i, 'Error:', err_fold, 'Valid Error:', err_valid_fold, 'Fraud Error', err_fraud_fold)\n",
    "        #err += err_fold\n",
    "        #err_valid += err_valid_fold\n",
    "        #err_fraud += err_fraud_fold\n",
    "        conf_mat = confusion_matrix(labels[folds[i]], pred)\n",
    "        fpr, tpr, thresholds = roc_curve(labels[folds[i]], pred1)\n",
    "        area_under_curve = auc(fpr, tpr)\n",
    "        AU += area_under_curve\n",
    "        print('Fold', i)\n",
    "        print(conf_mat)\n",
    "        print('Area under curve:', area_under_curve)\n",
    "\n",
    "        confusion_mat += conf_mat\n",
    "    AU/=5\n",
    "    confusion_mat /= 5\n",
    "    print('Final Confusion Matrix')\n",
    "    print(confusion_mat)\n",
    "    return confusion_mat, AU\n",
    "    #err /= 5\n",
    "    #err_valid /= 5\n",
    "    #err_fraud /= 5\n",
    "    #print('FINAL Error:', err, 'Valid Error:', err_valid, 'Fraud Error', err_fraud)\n",
    "    #return err, err_valid, err_fraud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression with Scaling, Class Weights, and Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking class weight None and coefficient 0.01\n",
      "Fold 0\n",
      "[[2822    3]\n",
      " [  19   80]]\n",
      "Area under curve: 0.9530955573433448\n",
      "Fold 1\n",
      "[[2823    1]\n",
      " [  19   80]]\n",
      "Area under curve: 0.9617062981085645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rupesh/.virtualenvs/dana3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/rupesh/.virtualenvs/dana3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/rupesh/.virtualenvs/dana3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2\n",
      "[[2821    3]\n",
      " [  23   75]]\n",
      "Area under curve: 0.9330230675839741\n",
      "Fold 3\n",
      "[[2822    2]\n",
      " [  19   79]]\n",
      "Area under curve: 0.973579233393074\n",
      "Fold 4\n",
      "[[2822    2]\n",
      " [  16   82]]\n",
      "Area under curve: 0.9583887379314332\n",
      "Final Confusion Matrix\n",
      "[[2.822e+03 2.200e+00]\n",
      " [1.920e+01 7.920e+01]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rupesh/.virtualenvs/dana3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/rupesh/.virtualenvs/dana3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 3, got 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-0ff53266db95>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mC\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparam_permuations\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Checking class weight {} and coefficient {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_logistic_regression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mfraud_errs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 3, got 2)"
     ]
    }
   ],
   "source": [
    "weights = [None,'balanced']\n",
    "coefficients = np.logspace(-2,0,10)\n",
    "fraud_errs = []\n",
    "param_permuations = list(itertools.product(weights, coefficients))\n",
    "for cw,C in param_permuations:\n",
    "    print('Checking class weight {} and coefficient {}'.format(cw, C))\n",
    "    _,_,fe = train_logistic_regression(data, cw, C)\n",
    "    fraud_errs.append(fe)\n",
    "\n",
    "idx = np.argmin(fraud_errs)\n",
    "best_params = param_permuations[idx]\n",
    "print('Best parameters found for Logistic Regression is {} class weights and {} coefficient'.format(best_params[0], best_params[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We see that as we improve fraud accuracy, valid accuracy decreases and vice versa. For the best fraud accuracy, the results suggest that we utilize the scaled data, balanced class weights and a strong regularization (small C coefficient)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_KNN(data, k, scale=False):\n",
    "    confusion_mat = np.zeros((2, 2))\n",
    "    for i in range(5):\n",
    "        knn = KNeighborsClassifier(n_neighbors=k)\n",
    "        \n",
    "        train_data = np.delete(data, folds[i], axis=0)\n",
    "        test_data = data[folds[i]]\n",
    "        if scale:\n",
    "            scaler = StandardScaler()\n",
    "            train_data = scaler.fit_transform(train_data)\n",
    "            test_data = scaler.transform(test_data)\n",
    "\n",
    "        knn.fit(train_data, np.delete(labels, folds[i]))\n",
    "        pred = knn.predict(test_data)\n",
    "\n",
    "        conf_mat = confusion_matrix(labels[folds[i]], pred)\n",
    "        print('Fold', i)\n",
    "        print(conf_mat)\n",
    "\n",
    "        confusion_mat += conf_mat\n",
    "\n",
    "    confusion_mat /= 5\n",
    "    print('Final Confusion Matrix')\n",
    "    print(confusion_mat)\n",
    "    print('False negatives (valid):', confusion_mat[0, 1] / sum(confusion_mat[0, :]))\n",
    "    print('False positives (fraud):', confusion_mat[1, 0] / sum(confusion_mat[1,:]))\n",
    "    return confusion_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0\n",
      "[[2824    1]\n",
      " [  22   77]]\n",
      "Fold 1\n",
      "[[2823    1]\n",
      " [  26   73]]\n",
      "Fold 2\n",
      "[[2821    3]\n",
      " [  33   65]]\n",
      "Fold 3\n",
      "[[2822    2]\n",
      " [  28   70]]\n",
      "Fold 4\n",
      "[[2823    1]\n",
      " [  24   74]]\n",
      "Final Confusion Matrix\n",
      "[[2.8226e+03 1.6000e+00]\n",
      " [2.6600e+01 7.1800e+01]]\n",
      "False negatives (valid): 0.0005665321152892855\n",
      "False positives (fraud): 0.2703252032520325\n",
      "Confusion Matrix:\n",
      "[[2.8226e+03 1.6000e+00]\n",
      " [2.6600e+01 7.1800e+01]]\n",
      "\n",
      "Fold 0\n",
      "[[2824    1]\n",
      " [  25   74]]\n",
      "Fold 1\n",
      "[[2823    1]\n",
      " [  29   70]]\n",
      "Fold 2\n",
      "[[2821    3]\n",
      " [  40   58]]\n",
      "Fold 3\n",
      "[[2823    1]\n",
      " [  31   67]]\n",
      "Fold 4\n",
      "[[2823    1]\n",
      " [  31   67]]\n",
      "Final Confusion Matrix\n",
      "[[2.8228e+03 1.4000e+00]\n",
      " [3.1200e+01 6.7200e+01]]\n",
      "False negatives (valid): 0.0004957156008781247\n",
      "False positives (fraud): 0.31707317073170727\n",
      "Confusion Matrix:\n",
      "[[2.8228e+03 1.4000e+00]\n",
      " [3.1200e+01 6.7200e+01]]\n",
      "\n",
      "Fold 0\n",
      "[[2824    1]\n",
      " [  27   72]]\n",
      "Fold 1\n",
      "[[2823    1]\n",
      " [  31   68]]\n",
      "Fold 2\n",
      "[[2821    3]\n",
      " [  40   58]]\n",
      "Fold 3\n",
      "[[2823    1]\n",
      " [  34   64]]\n",
      "Fold 4\n",
      "[[2823    1]\n",
      " [  31   67]]\n",
      "Final Confusion Matrix\n",
      "[[2.8228e+03 1.4000e+00]\n",
      " [3.2600e+01 6.5800e+01]]\n",
      "False negatives (valid): 0.0004957156008781247\n",
      "False positives (fraud): 0.3313008130081301\n",
      "Confusion Matrix:\n",
      "[[2.8228e+03 1.4000e+00]\n",
      " [3.2600e+01 6.5800e+01]]\n",
      "\n",
      "Fold 0\n",
      "[[2824    1]\n",
      " [  31   68]]\n",
      "Fold 1\n",
      "[[2823    1]\n",
      " [  32   67]]\n",
      "Fold 2\n",
      "[[2822    2]\n",
      " [  40   58]]\n",
      "Fold 3\n",
      "[[2823    1]\n",
      " [  36   62]]\n",
      "Fold 4\n",
      "[[2823    1]\n",
      " [  39   59]]\n",
      "Final Confusion Matrix\n",
      "[[2.823e+03 1.200e+00]\n",
      " [3.560e+01 6.280e+01]]\n",
      "False negatives (valid): 0.0004248990864669641\n",
      "False positives (fraud): 0.36178861788617883\n",
      "Confusion Matrix:\n",
      "[[2.823e+03 1.200e+00]\n",
      " [3.560e+01 6.280e+01]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for k in [5, 7, 9, 11]:\n",
    "    conf = train_KNN(data, k)\n",
    "    print('Confusion Matrix:')\n",
    "    print(conf)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
