{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import itertools\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# import warnings\n",
    "# warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the data\n",
    "\n",
    "Note about the data: The dataset is rather large, and very skewed toward valid transactions. To balance it a bit better, we sample and only keep around 5% of the valid transactions (the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data is imbalanced, with 14850 samples in total but only 492 cases of fraud\n"
     ]
    }
   ],
   "source": [
    "with open('creditcard.csv', newline='') as f:\n",
    "    reader = csv.reader(f, delimiter=',')\n",
    "    csv_data = list(reader)[1:]\n",
    "    \n",
    "csv_data = [row for row in csv_data if int(row[-1]) == 1 or random.random() < .05]\n",
    "\n",
    "# Format: Time, V1, ..., V28, Amount, Class\n",
    "data = np.array([[float(x) for x in row[1:-1]] for row in csv_data])\n",
    "times = np.array([float(row[0]) for row in csv_data])\n",
    "labels = np.array([int(row[-1]) for row in csv_data])\n",
    "print('The data is imbalanced, with {} samples in total but only {} cases of fraud'.format(len(labels), sum(labels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.04069949e-01  1.14337601e-01 -2.39954236e-01  1.49773023e-01\n",
      " -1.04335949e-01 -4.76659013e-02 -1.69266234e-01  1.10440096e-02\n",
      " -9.66701849e-02 -1.90833829e-01  1.21325044e-01 -1.88709551e-01\n",
      "  4.18786724e-03 -2.19663133e-01 -7.98572937e-04 -1.28596900e-01\n",
      " -2.11535686e-01 -6.32431669e-02  2.55453257e-02  1.29440167e-02\n",
      "  2.60525408e-02  5.68798847e-03 -6.10256394e-03 -8.00962273e-03\n",
      "  6.54633644e-03  4.40102652e-03  8.57899617e-03  4.81988286e-03\n",
      "  9.03701185e+01]\n",
      "[5.55541747e+00 3.28250204e+00 5.23991156e+00 2.80995594e+00\n",
      " 2.83495549e+00 1.80627515e+00 3.89873352e+00 2.82662321e+00\n",
      " 1.50831630e+00 2.81131711e+00 1.69336850e+00 2.84124896e+00\n",
      " 9.95339209e-01 2.95810943e+00 8.27560303e-01 1.74164039e+00\n",
      " 3.58889125e+00 1.08994272e+00 7.20415463e-01 5.68059640e-01\n",
      " 9.94845898e-01 5.75998690e-01 3.90938924e-01 3.62947766e-01\n",
      " 2.78912282e-01 2.31337319e-01 1.94601528e-01 9.03360443e-02\n",
      " 5.75558970e+04]\n",
      "The PCA features have mean 0 but different variances\n",
      "The transaction amount is not scaled. We should scale it so it does not affect the SVM too much\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(data, axis=0))\n",
    "print(np.var(data, axis=0))\n",
    "print('The PCA features have mean 0 but different variances')\n",
    "print('The transaction amount is not scaled. We should scale it so it does not affect the SVM too much')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 5.59349611e-16  3.01954496e-16 -5.93651578e-17 -1.69800575e-16\n",
      "  6.68197260e-16 -2.47187231e-16  1.65512946e-16  1.81079431e-16\n",
      " -1.49064263e-16  1.38553591e-15  7.54133007e-16 -1.30753993e-16\n",
      "  1.16479964e-16 -3.26413045e-17  1.01826516e-17 -1.38699377e-16\n",
      " -2.46592870e-16 -1.53195825e-16  4.56154007e-17  2.74027901e-18\n",
      " -1.87280046e-17 -4.90845673e-16 -1.48402615e-16  5.15879894e-17\n",
      "  1.14483806e-16  2.52654239e-16  1.99881264e-16  9.21971067e-17\n",
      "  7.60295680e-15]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "data_sc = scaler.fit_transform(data)\n",
    "print(np.mean(data_sc, axis=0))\n",
    "print(np.var(data_sc, axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preliminary plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.55406456  1.15431212  1.14736893 -0.65830493  1.03837033  1.27613378\n",
      "  1.08103308  0.8056818  -0.86856533]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the first two principal components\n",
    "data_fraud = data[np.where(labels == 1)]\n",
    "data_valid = data[np.where(labels == 0)]\n",
    "plt.scatter(data_valid[:, 0], data_valid[:, -1], c='b')\n",
    "plt.scatter(data_fraud[:, 0], data_fraud[:, -1], c='r')\n",
    "print(data_valid[1:10, 0])\n",
    "plt.ylim((0, 10000))\n",
    "plt.legend(['valid', 'fraud'])\n",
    "plt.xlabel('First PCA feature')\n",
    "plt.ylabel('Transaction amount')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraud_indices = np.where(labels == 1)[0]\n",
    "np.random.shuffle(fraud_indices)\n",
    "fraud_splits = np.array_split(fraud_indices, 5)\n",
    "\n",
    "valid_indices = np.where(labels == 0)[0]\n",
    "np.random.shuffle(valid_indices)\n",
    "valid_splits = np.array_split(valid_indices, 5)\n",
    "\n",
    "folds = [np.concatenate((fraud_sp, valid_sp)) for fraud_sp, valid_sp in zip(fraud_splits, valid_splits)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_binary_SVM(data, scale=False, kernel=None, class_weight=None):\n",
    "    confusion_mat = np.zeros((2, 2))\n",
    "    for i in range(5):\n",
    "        if kernel is None:\n",
    "            if class_weight is None:\n",
    "                svm = LinearSVC(fit_intercept=False, dual=False)\n",
    "            else:\n",
    "                svm = LinearSVC(fit_intercept=False, dual=False, class_weight=class_weight)\n",
    "        else:\n",
    "            if class_weight is None:\n",
    "                svm = SVC(kernel=kernel, gamma='auto')\n",
    "            else:\n",
    "                svm = SVC(kernel=kernel, gamma='auto', class_weight=class_weight)\n",
    "        \n",
    "        train_data = np.delete(data, folds[i], axis=0)\n",
    "        test_data = data[folds[i]]\n",
    "        if scale:\n",
    "            scaler = StandardScaler()\n",
    "            train_data = scaler.fit_transform(train_data)\n",
    "            test_data = scaler.transform(test_data)\n",
    "\n",
    "        svm.fit(train_data, np.delete(labels, folds[i]))\n",
    "        pred = svm.predict(test_data)\n",
    "\n",
    "        conf_mat = confusion_matrix(labels[folds[i]], pred)\n",
    "        print('Fold', i)\n",
    "        print(conf_mat)\n",
    "\n",
    "        confusion_mat += conf_mat\n",
    "\n",
    "    confusion_mat /= 5\n",
    "    print('Final Confusion Matrix')\n",
    "    print(confusion_mat)\n",
    "    print('False negatives (valid):', confusion_mat[0, 1] / sum(confusion_mat[0, :]))\n",
    "    print('False positives (fraud):', confusion_mat[1, 0] / sum(confusion_mat[1,:]))\n",
    "    return confusion_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear SVM -- Without scaling or class weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0\n",
      "[[2866    6]\n",
      " [  18   81]]\n",
      "Fold 1\n",
      "[[2861   11]\n",
      " [  19   80]]\n",
      "Fold 2\n",
      "[[2857   15]\n",
      " [  29   69]]\n",
      "Fold 3\n",
      "[[2861   10]\n",
      " [  30   68]]\n",
      "Fold 4\n",
      "[[2860   11]\n",
      " [  18   80]]\n",
      "Final Confusion Matrix\n",
      "[[2861.    10.6]\n",
      " [  22.8   75.6]]\n",
      "False negatives (valid): 0.003691321911129684\n",
      "False positives (fraud): 0.23170731707317077\n"
     ]
    }
   ],
   "source": [
    "train_binary_SVM(data);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear SVM with Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0\n",
      "[[2867    5]\n",
      " [  17   82]]\n",
      "Fold 1\n",
      "[[2868    4]\n",
      " [  17   82]]\n",
      "Fold 2\n",
      "[[2870    2]\n",
      " [  22   76]]\n",
      "Fold 3\n",
      "[[2865    6]\n",
      " [  20   78]]\n",
      "Fold 4\n",
      "[[2869    2]\n",
      " [  14   84]]\n",
      "Final Confusion Matrix\n",
      "[[2867.8    3.8]\n",
      " [  18.    80.4]]\n",
      "False negatives (valid): 0.001323304081348377\n",
      "False positives (fraud): 0.18292682926829268\n"
     ]
    }
   ],
   "source": [
    "train_binary_SVM(data, scale=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear SVM with Scaling and Class Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0\n",
      "[[2775   97]\n",
      " [   9   90]]\n",
      "Fold 1\n",
      "[[2783   89]\n",
      " [  10   89]]\n",
      "Fold 2\n",
      "[[2780   92]\n",
      " [   6   92]]\n",
      "Fold 3\n",
      "[[2739  132]\n",
      " [  11   87]]\n",
      "Fold 4\n",
      "[[2764  107]\n",
      " [   6   92]]\n",
      "Final Confusion Matrix\n",
      "[[2768.2  103.4]\n",
      " [   8.4   90. ]]\n",
      "False negatives (valid): 0.036007800529321635\n",
      "False positives (fraud): 0.08536585365853658\n"
     ]
    }
   ],
   "source": [
    "train_binary_SVM(data, scale=True, class_weight='balanced');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kernel SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RBF Kernel with Scaling and Class Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0\n",
      "[[2871    1]\n",
      " [  21   78]]\n",
      "Fold 1\n",
      "[[2870    2]\n",
      " [  20   79]]\n",
      "Fold 2\n",
      "[[2870    2]\n",
      " [  25   73]]\n",
      "Fold 3\n",
      "[[2870    1]\n",
      " [  20   78]]\n",
      "Fold 4\n",
      "[[2870    1]\n",
      " [  19   79]]\n",
      "Final Confusion Matrix\n",
      "[[2.8702e+03 1.4000e+00]\n",
      " [2.1000e+01 7.7400e+01]]\n",
      "False negatives (valid): 0.0004875330826020337\n",
      "False positives (fraud): 0.21341463414634146\n"
     ]
    }
   ],
   "source": [
    "train_binary_SVM(data, scale=True, kernel='rbf');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0\n",
      "[[2861   11]\n",
      " [  48   51]]\n",
      "Fold 1\n",
      "[[2865    7]\n",
      " [  55   44]]\n",
      "Fold 2\n",
      "[[2863    9]\n",
      " [  46   52]]\n",
      "Fold 3\n",
      "[[2858   13]\n",
      " [  50   48]]\n",
      "Fold 4\n",
      "[[2859   12]\n",
      " [  46   52]]\n",
      "Final Confusion Matrix\n",
      "[[2861.2   10.4]\n",
      " [  49.    49.4]]\n",
      "False negatives (valid): 0.003621674327900822\n",
      "False positives (fraud): 0.4979674796747967\n"
     ]
    }
   ],
   "source": [
    "train_binary_SVM(data, kernel='rbf', class_weight='balanced');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Polynomial Kernel with Scaling and Class Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0\n",
      "[[2870    2]\n",
      " [  19   80]]\n",
      "Fold 1\n",
      "[[2869    3]\n",
      " [  21   78]]\n",
      "Fold 2\n",
      "[[2866    6]\n",
      " [  21   77]]\n",
      "Fold 3\n",
      "[[2866    5]\n",
      " [  25   73]]\n",
      "Fold 4\n",
      "[[2868    3]\n",
      " [  12   86]]\n",
      "Final Confusion Matrix\n",
      "[[2867.8    3.8]\n",
      " [  19.6   78.8]]\n",
      "False negatives (valid): 0.001323304081348377\n",
      "False positives (fraud): 0.1991869918699187\n"
     ]
    }
   ],
   "source": [
    "train_binary_SVM(data, scale=True, kernel='poly');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0\n",
      "[[2852   20]\n",
      " [  16   83]]\n",
      "Fold 1\n",
      "[[2852   20]\n",
      " [  17   82]]\n",
      "Fold 2\n",
      "[[2851   21]\n",
      " [  13   85]]\n",
      "Fold 3\n",
      "[[2847   24]\n",
      " [  18   80]]\n",
      "Fold 4\n",
      "[[2849   22]\n",
      " [  13   85]]\n",
      "Final Confusion Matrix\n",
      "[[2850.2   21.4]\n",
      " [  15.4   83. ]]\n",
      "False negatives (valid): 0.00745229140548823\n",
      "False positives (fraud): 0.1565040650406504\n"
     ]
    }
   ],
   "source": [
    "train_binary_SVM(data, scale=True, kernel='poly', class_weight='balanced');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_logistic_regression(data, folds, labels, class_weight = None, C=1.0):\n",
    "    err = 0\n",
    "    err_valid = 0\n",
    "    err_fraud = 0\n",
    "    confusion_mat = np.zeros((2, 2))\n",
    "    AU = 0\n",
    "    for i in range(5):\n",
    "        model = LogisticRegression(class_weight=class_weight, C=C)\n",
    "        \n",
    "        model.fit(np.delete(data, folds[i], axis=0), np.delete(labels, folds[i]))\n",
    "        pred = model.predict(data[folds[i]])\n",
    "        pred1 = model.predict_proba(data[folds[i]])[:,1]\n",
    "        conf_mat = confusion_matrix(labels[folds[i]], pred)\n",
    "        fpr, tpr, thresholds = roc_curve(labels[folds[i]], pred1)\n",
    "        area_under_curve = auc(fpr, tpr)\n",
    "        AU += area_under_curve\n",
    "        print('Fold', i)\n",
    "        print(conf_mat)\n",
    "        print('Area under curve:', area_under_curve)\n",
    "\n",
    "        confusion_mat += conf_mat\n",
    "    AU/=5\n",
    "    confusion_mat /= 5\n",
    "    print('Final Confusion Matrix')\n",
    "    print(confusion_mat)\n",
    "    return confusion_mat, AU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression with Scaling, Class Weights, and Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking class weight None and coefficient 0.01\n",
      "Fold 0\n",
      "[[2871    1]\n",
      " [  17   82]]\n",
      "Area under curve: 0.9870220308938972\n",
      "Fold 1\n",
      "[[2870    2]\n",
      " [  16   83]]\n",
      "Area under curve: 0.9770546692552264\n",
      "Fold 2\n",
      "[[2870    2]\n",
      " [  22   76]]\n",
      "Area under curve: 0.9786005627877892\n",
      "Fold 3\n",
      "[[2870    1]\n",
      " [  20   78]]\n",
      "Area under curve: 0.9749820513367311\n",
      "Fold 4\n",
      "[[2870    1]\n",
      " [  14   84]]\n",
      "Area under curve: 0.9795420780642455\n",
      "Final Confusion Matrix\n",
      "[[2.8702e+03 1.4000e+00]\n",
      " [1.7800e+01 8.0600e+01]]\n",
      "F1 score: 0.893569844789357\n",
      "Recall: 0.8191056910569106\n",
      "Precision: 0.9829268292682927\n",
      "AUC: 0.9794402784675779\n",
      "Checking class weight None and coefficient 0.016681005372000592\n",
      "Fold 0\n",
      "[[2871    1]\n",
      " [  17   82]]\n",
      "Area under curve: 0.9874616639936975\n",
      "Fold 1\n",
      "[[2870    2]\n",
      " [  15   84]]\n",
      "Area under curve: 0.9770617033848232\n",
      "Fold 2\n",
      "[[2870    2]\n",
      " [  22   76]]\n",
      "Area under curve: 0.9794710363253938\n",
      "Fold 3\n",
      "[[2870    1]\n",
      " [  20   78]]\n",
      "Area under curve: 0.9751704234462855\n",
      "Fold 4\n",
      "[[2870    1]\n",
      " [  14   84]]\n",
      "Area under curve: 0.9799472558093247\n",
      "Final Confusion Matrix\n",
      "[[2.8702e+03 1.4000e+00]\n",
      " [1.7600e+01 8.0800e+01]]\n",
      "F1 score: 0.8947951273532667\n",
      "Recall: 0.8211382113821137\n",
      "Precision: 0.9829683698296836\n",
      "AUC: 0.979822416591905\n",
      "Checking class weight None and coefficient 0.027825594022071243\n",
      "Fold 0\n",
      "[[2871    1]\n",
      " [  17   82]]\n",
      "Area under curve: 0.9877184097239807\n",
      "Fold 1\n",
      "[[2870    2]\n",
      " [  15   84]]\n",
      "Area under curve: 0.9770300498016375\n",
      "Fold 2\n",
      "[[2870    2]\n",
      " [  21   77]]\n",
      "Area under curve: 0.9803876982547893\n",
      "Fold 3\n",
      "[[2870    1]\n",
      " [  20   78]]\n",
      "Area under curve: 0.9753232536483768\n",
      "Fold 4\n",
      "[[2869    2]\n",
      " [  14   84]]\n",
      "Area under curve: 0.9801960491615664\n",
      "Final Confusion Matrix\n",
      "[[2.87e+03 1.60e+00]\n",
      " [1.74e+01 8.10e+01]]\n",
      "F1 score: 0.8950276243093923\n",
      "Recall: 0.823170731707317\n",
      "Precision: 0.9806295399515739\n",
      "AUC: 0.9801310921180703\n",
      "Checking class weight None and coefficient 0.046415888336127774\n",
      "Fold 0\n",
      "[[2871    1]\n",
      " [  17   82]]\n",
      "Area under curve: 0.9878098534087392\n",
      "Fold 1\n",
      "[[2870    2]\n",
      " [  16   83]]\n",
      "Area under curve: 0.9772656931431305\n",
      "Fold 2\n",
      "[[2870    2]\n",
      " [  20   78]]\n",
      "Area under curve: 0.9812972542777556\n",
      "Fold 3\n",
      "[[2870    1]\n",
      " [  21   77]]\n",
      "Area under curve: 0.9751064480128518\n",
      "Fold 4\n",
      "[[2869    2]\n",
      " [  14   84]]\n",
      "Area under curve: 0.9803382167914187\n",
      "Final Confusion Matrix\n",
      "[[2.87e+03 1.60e+00]\n",
      " [1.76e+01 8.08e+01]]\n",
      "F1 score: 0.8938053097345132\n",
      "Recall: 0.8211382113821137\n",
      "Precision: 0.9805825242718448\n",
      "AUC: 0.9803634931267791\n",
      "Checking class weight None and coefficient 0.0774263682681127\n",
      "Fold 0\n",
      "[[2870    2]\n",
      " [  17   82]]\n",
      "Area under curve: 0.987739512112771\n",
      "Fold 1\n",
      "[[2869    3]\n",
      " [  16   83]]\n",
      "Area under curve: 0.9777299456965195\n",
      "Fold 2\n",
      "[[2870    2]\n",
      " [  20   78]]\n",
      "Area under curve: 0.9821854925814337\n",
      "Fold 3\n",
      "[[2870    1]\n",
      " [  21   77]]\n",
      "Area under curve: 0.9744133808173217\n",
      "Fold 4\n",
      "[[2869    2]\n",
      " [  14   84]]\n",
      "Area under curve: 0.9800858692484309\n",
      "Final Confusion Matrix\n",
      "[[2.8696e+03 2.0000e+00]\n",
      " [1.7600e+01 8.0800e+01]]\n",
      "F1 score: 0.8918322295805738\n",
      "Recall: 0.8211382113821137\n",
      "Precision: 0.9758454106280193\n",
      "AUC: 0.9804308400912956\n",
      "Checking class weight None and coefficient 0.1291549665014884\n",
      "Fold 0\n",
      "[[2871    1]\n",
      " [  17   82]]\n",
      "Area under curve: 0.9874053909569229\n",
      "Fold 1\n",
      "[[2869    3]\n",
      " [  16   83]]\n",
      "Area under curve: 0.9782961931290622\n",
      "Fold 2\n",
      "[[2870    2]\n",
      " [  20   78]]\n",
      "Area under curve: 0.9828996361775907\n",
      "Fold 3\n",
      "[[2870    1]\n",
      " [  20   78]]\n",
      "Area under curve: 0.9732902565414882\n",
      "Fold 4\n",
      "[[2869    2]\n",
      " [  14   84]]\n",
      "Area under curve: 0.9796415954051422\n",
      "Final Confusion Matrix\n",
      "[[2.8698e+03 1.8000e+00]\n",
      " [1.7400e+01 8.1000e+01]]\n",
      "F1 score: 0.8940397350993378\n",
      "Recall: 0.823170731707317\n",
      "Precision: 0.9782608695652174\n",
      "AUC: 0.9803066144420413\n",
      "Checking class weight None and coefficient 0.21544346900318834\n",
      "Fold 0\n",
      "[[2871    1]\n",
      " [  17   82]]\n",
      "Area under curve: 0.9868602459131708\n",
      "Fold 1\n",
      "[[2869    3]\n",
      " [  16   83]]\n",
      "Area under curve: 0.9785986607017247\n",
      "Fold 2\n",
      "[[2870    2]\n",
      " [  20   78]]\n",
      "Area under curve: 0.9832833551247797\n",
      "Fold 3\n",
      "[[2870    1]\n",
      " [  20   78]]\n",
      "Area under curve: 0.9720285188265484\n",
      "Fold 4\n",
      "[[2869    2]\n",
      " [  14   84]]\n",
      "Area under curve: 0.9791049126024496\n",
      "Final Confusion Matrix\n",
      "[[2.8698e+03 1.8000e+00]\n",
      " [1.7400e+01 8.1000e+01]]\n",
      "F1 score: 0.8940397350993378\n",
      "Recall: 0.823170731707317\n",
      "Precision: 0.9782608695652174\n",
      "AUC: 0.9799751386337346\n",
      "Checking class weight None and coefficient 0.3593813663804626\n",
      "Fold 0\n",
      "[[2871    1]\n",
      " [  16   83]]\n",
      "Area under curve: 0.9861568329534903\n",
      "Fold 1\n",
      "[[2869    3]\n",
      " [  16   83]]\n",
      "Area under curve: 0.9786408654793056\n",
      "Fold 2\n",
      "[[2870    2]\n",
      " [  20   78]]\n",
      "Area under curve: 0.9835498266158831\n",
      "Fold 3\n",
      "[[2870    1]\n",
      " [  20   78]]\n",
      "Area under curve: 0.9708627442617589\n",
      "Fold 4\n",
      "[[2869    2]\n",
      " [  15   83]]\n",
      "Area under curve: 0.9786073258979663\n",
      "Final Confusion Matrix\n",
      "[[2.8698e+03 1.8000e+00]\n",
      " [1.7400e+01 8.1000e+01]]\n",
      "F1 score: 0.8940397350993378\n",
      "Recall: 0.823170731707317\n",
      "Precision: 0.9782608695652174\n",
      "AUC: 0.9795635190416808\n",
      "Checking class weight None and coefficient 0.5994842503189409\n",
      "Fold 0\n",
      "[[2871    1]\n",
      " [  16   83]]\n",
      "Area under curve: 0.985558931937762\n",
      "Fold 1\n",
      "[[2869    3]\n",
      " [  17   82]]\n",
      "Area under curve: 0.9786162460257168\n",
      "Fold 2\n",
      "[[2870    2]\n",
      " [  19   79]]\n",
      "Area under curve: 0.9837274742766187\n",
      "Fold 3\n",
      "[[2870    1]\n",
      " [  20   78]]\n",
      "Area under curve: 0.9699493172399577\n",
      "Fold 4\n",
      "[[2869    2]\n",
      " [  15   83]]\n",
      "Area under curve: 0.978120401765722\n",
      "Final Confusion Matrix\n",
      "[[2.8698e+03 1.8000e+00]\n",
      " [1.7400e+01 8.1000e+01]]\n",
      "F1 score: 0.8940397350993378\n",
      "Recall: 0.823170731707317\n",
      "Precision: 0.9782608695652174\n",
      "AUC: 0.9791944742491554\n",
      "Checking class weight None and coefficient 1.0\n",
      "Fold 0\n",
      "[[2871    1]\n",
      " [  17   82]]\n",
      "Area under curve: 0.9850911623195746\n",
      "Fold 1\n",
      "[[2869    3]\n",
      " [  17   82]]\n",
      "Area under curve: 0.9785705241833377\n",
      "Fold 2\n",
      "[[2870    2]\n",
      " [  19   79]]\n",
      "Area under curve: 0.9838091922005571\n",
      "Fold 3\n",
      "[[2870    1]\n",
      " [  20   78]]\n",
      "Area under curve: 0.9691816120387549\n",
      "Fold 4\n",
      "[[2869    2]\n",
      " [  15   83]]\n",
      "Area under curve: 0.9778147413615392\n",
      "Final Confusion Matrix\n",
      "[[2.8698e+03 1.8000e+00]\n",
      " [1.7600e+01 8.0800e+01]]\n",
      "F1 score: 0.8928176795580111\n",
      "Recall: 0.8211382113821137\n",
      "Precision: 0.9782082324455206\n",
      "AUC: 0.9788934464207528\n",
      "Checking class weight balanced and coefficient 0.01\n",
      "Fold 0\n",
      "[[2819   53]\n",
      " [  11   88]]\n",
      "Area under curve: 0.9854217664106243\n",
      "Fold 1\n",
      "[[2811   61]\n",
      " [  12   87]]\n",
      "Area under curve: 0.9684062069159562\n",
      "Fold 2\n",
      "[[2826   46]\n",
      " [   8   90]]\n",
      "Area under curve: 0.9841360638963108\n",
      "Fold 3\n",
      "[[2803   68]\n",
      " [  12   86]]\n",
      "Area under curve: 0.9759985498901755\n",
      "Fold 4\n",
      "[[2791   80]\n",
      " [   6   92]]\n",
      "Area under curve: 0.9800680982946993\n",
      "Final Confusion Matrix\n",
      "[[2810.    61.6]\n",
      " [   9.8   88.6]]\n",
      "F1 score: 0.7127916331456154\n",
      "Recall: 0.9004065040650406\n",
      "Precision: 0.5898801597869507\n",
      "AUC: 0.9788061370815534\n",
      "Checking class weight balanced and coefficient 0.016681005372000592\n",
      "Fold 0\n",
      "[[2818   54]\n",
      " [  11   88]]\n",
      "Area under curve: 0.985217776652317\n",
      "Fold 1\n",
      "[[2810   62]\n",
      " [  12   87]]\n",
      "Area under curve: 0.9683393826847866\n",
      "Fold 2\n",
      "[[2821   51]\n",
      " [   7   91]]\n",
      "Area under curve: 0.9841396168495253\n",
      "Fold 3\n",
      "[[2803   68]\n",
      " [  12   86]]\n",
      "Area under curve: 0.9755436134746479\n",
      "Fold 4\n",
      "[[2790   81]\n",
      " [   6   92]]\n",
      "Area under curve: 0.9798690636129059\n",
      "Final Confusion Matrix\n",
      "[[2808.4   63.2]\n",
      " [   9.6   88.8]]\n",
      "F1 score: 0.7092651757188497\n",
      "Recall: 0.9024390243902439\n",
      "Precision: 0.5842105263157894\n",
      "AUC: 0.9786218906548365\n",
      "Checking class weight balanced and coefficient 0.027825594022071243\n",
      "Fold 0\n",
      "[[2820   52]\n",
      " [  11   88]]\n",
      "Area under curve: 0.9849223432092513\n",
      "Fold 1\n",
      "[[2811   61]\n",
      " [  12   87]]\n",
      "Area under curve: 0.968230353676036\n",
      "Fold 2\n",
      "[[2817   55]\n",
      " [   7   91]]\n",
      "Area under curve: 0.9841254050366666\n",
      "Fold 3\n",
      "[[2800   71]\n",
      " [  12   86]]\n",
      "Area under curve: 0.9750815686776279\n",
      "Fold 4\n",
      "[[2790   81]\n",
      " [   6   92]]\n",
      "Area under curve: 0.9797517753182777\n",
      "Final Confusion Matrix\n",
      "[[2807.6   64. ]\n",
      " [   9.6   88.8]]\n",
      "F1 score: 0.7070063694267514\n",
      "Recall: 0.9024390243902439\n",
      "Precision: 0.5811518324607329\n",
      "AUC: 0.978422289183572\n",
      "Checking class weight balanced and coefficient 0.046415888336127774\n",
      "Fold 0\n",
      "[[2819   53]\n",
      " [  10   89]]\n",
      "Area under curve: 0.9845882220534031\n",
      "Fold 1\n",
      "[[2809   63]\n",
      " [  11   88]]\n",
      "Area under curve: 0.9679947103345431\n",
      "Fold 2\n",
      "[[2817   55]\n",
      " [   7   91]]\n",
      "Area under curve: 0.9841858052413166\n",
      "Fold 3\n",
      "[[2800   71]\n",
      " [  12   86]]\n",
      "Area under curve: 0.9744560311062774\n",
      "Fold 4\n",
      "[[2791   80]\n",
      " [   6   92]]\n",
      "Area under curve: 0.9795847283532012\n",
      "Final Confusion Matrix\n",
      "[[2807.2   64.4]\n",
      " [   9.2   89.2]]\n",
      "F1 score: 0.7079365079365079\n",
      "Recall: 0.9065040650406504\n",
      "Precision: 0.5807291666666666\n",
      "AUC: 0.9781618994177483\n",
      "Checking class weight balanced and coefficient 0.0774263682681127\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0\n",
      "[[2820   52]\n",
      " [  10   89]]\n",
      "Area under curve: 0.984306856869531\n",
      "Fold 1\n",
      "[[2808   64]\n",
      " [  10   89]]\n",
      "Area under curve: 0.9678329253538167\n",
      "Fold 2\n",
      "[[2817   55]\n",
      " [   7   91]]\n",
      "Area under curve: 0.984242652492752\n",
      "Fold 3\n",
      "[[2799   72]\n",
      " [  12   86]]\n",
      "Area under curve: 0.97393356506657\n",
      "Fold 4\n",
      "[[2792   79]\n",
      " [   6   92]]\n",
      "Area under curve: 0.9795580719226039\n",
      "Final Confusion Matrix\n",
      "[[2807.2   64.4]\n",
      " [   9.    89.4]]\n",
      "F1 score: 0.7089611419508328\n",
      "Recall: 0.9085365853658537\n",
      "Precision: 0.5812743823146944\n",
      "AUC: 0.9779748143410547\n",
      "Checking class weight balanced and coefficient 0.1291549665014884\n",
      "Fold 0\n",
      "[[2820   52]\n",
      " [  10   89]]\n",
      "Area under curve: 0.9840043892968684\n",
      "Fold 1\n",
      "[[2809   63]\n",
      " [  10   89]]\n",
      "Area under curve: 0.9679067837145832\n",
      "Fold 2\n",
      "[[2814   58]\n",
      " [   7   91]]\n",
      "Area under curve: 0.9843208174634757\n",
      "Fold 3\n",
      "[[2797   74]\n",
      " [  12   86]]\n",
      "Area under curve: 0.9736279046623875\n",
      "Fold 4\n",
      "[[2789   82]\n",
      " [   6   92]]\n",
      "Area under curve: 0.979570511590216\n",
      "Final Confusion Matrix\n",
      "[[2805.8   65.8]\n",
      " [   9.    89.4]]\n",
      "F1 score: 0.7050473186119874\n",
      "Recall: 0.9085365853658537\n",
      "Precision: 0.5760309278350516\n",
      "AUC: 0.9778860813455061\n",
      "Checking class weight balanced and coefficient 0.21544346900318834\n",
      "Fold 0\n",
      "[[2822   50]\n",
      " [  10   89]]\n",
      "Area under curve: 0.9836913705298107\n",
      "Fold 1\n",
      "[[2809   63]\n",
      " [  10   89]]\n",
      "Area under curve: 0.9680333980473256\n",
      "Fold 2\n",
      "[[2813   59]\n",
      " [   7   91]]\n",
      "Area under curve: 0.9843563469956227\n",
      "Fold 3\n",
      "[[2796   75]\n",
      " [  12   86]]\n",
      "Area under curve: 0.9733506777841753\n",
      "Fold 4\n",
      "[[2790   81]\n",
      " [   6   92]]\n",
      "Area under curve: 0.9796913540755906\n",
      "Final Confusion Matrix\n",
      "[[2806.    65.6]\n",
      " [   9.    89.4]]\n",
      "F1 score: 0.7056037884767167\n",
      "Recall: 0.9085365853658537\n",
      "Precision: 0.5767741935483871\n",
      "AUC: 0.9778246294865051\n",
      "Checking class weight balanced and coefficient 0.3593813663804626\n",
      "Fold 0\n",
      "[[2820   52]\n",
      " [  10   89]]\n",
      "Area under curve: 0.9834029712163417\n",
      "Fold 1\n",
      "[[2808   64]\n",
      " [  10   89]]\n",
      "Area under curve: 0.9681987000928506\n",
      "Fold 2\n",
      "[[2813   59]\n",
      " [   7   91]]\n",
      "Area under curve: 0.9844274060599169\n",
      "Fold 3\n",
      "[[2794   77]\n",
      " [  12   86]]\n",
      "Area under curve: 0.9731623056746209\n",
      "Fold 4\n",
      "[[2790   81]\n",
      " [   6   92]]\n",
      "Area under curve: 0.9798068652748455\n",
      "Final Confusion Matrix\n",
      "[[2805.    66.6]\n",
      " [   9.    89.4]]\n",
      "F1 score: 0.7028301886792454\n",
      "Recall: 0.9085365853658537\n",
      "Precision: 0.5730769230769232\n",
      "AUC: 0.9777996496637151\n",
      "Checking class weight balanced and coefficient 0.5994842503189409\n",
      "Fold 0\n",
      "[[2820   52]\n",
      " [  10   89]]\n",
      "Area under curve: 0.9832869080779945\n",
      "Fold 1\n",
      "[[2808   64]\n",
      " [  10   89]]\n",
      "Area under curve: 0.9683815874623675\n",
      "Fold 2\n",
      "[[2813   59]\n",
      " [   7   91]]\n",
      "Area under curve: 0.9845091239838554\n",
      "Fold 3\n",
      "[[2792   79]\n",
      " [  12   86]]\n",
      "Area under curve: 0.9731018844319337\n",
      "Fold 4\n",
      "[[2789   82]\n",
      " [   6   92]]\n",
      "Area under curve: 0.9798992742342497\n",
      "Final Confusion Matrix\n",
      "[[2804.4   67.2]\n",
      " [   9.    89.4]]\n",
      "F1 score: 0.7011764705882352\n",
      "Recall: 0.9085365853658537\n",
      "Precision: 0.5708812260536398\n",
      "AUC: 0.9778357556380801\n",
      "Checking class weight balanced and coefficient 1.0\n",
      "Fold 0\n",
      "[[2819   53]\n",
      " [  10   89]]\n",
      "Area under curve: 0.9831813961340423\n",
      "Fold 1\n",
      "[[2807   65]\n",
      " [  10   89]]\n",
      "Area under curve: 0.9684994091331138\n",
      "Fold 2\n",
      "[[2813   59]\n",
      " [   7   91]]\n",
      "Area under curve: 0.9845304417031436\n",
      "Fold 3\n",
      "[[2793   78]\n",
      " [  12   86]]\n",
      "Area under curve: 0.973048571570739\n",
      "Fold 4\n",
      "[[2788   83]\n",
      " [   6   92]]\n",
      "Area under curve: 0.9800023457658925\n",
      "Final Confusion Matrix\n",
      "[[2804.    67.6]\n",
      " [   9.    89.4]]\n",
      "F1 score: 0.7000783085356304\n",
      "Recall: 0.9085365853658537\n",
      "Precision: 0.5694267515923567\n",
      "AUC: 0.9778524328613862\n",
      "Best parameters found for Logistic Regression under AUC metric is None class weights and 0.0774263682681127 coefficient\n",
      "Best parameters found for Logistic Regression under F1 metric is None class weights and 0.01 coefficient\n",
      "Best parameters found for Logistic Regression under precision metric is None class weights and 0.016681005372000592 coefficient\n",
      "Best parameters found for Logistic Regression under recall metric is balanced class weights and 0.0774263682681127 coefficient\n"
     ]
    }
   ],
   "source": [
    "weights = [None,'balanced']\n",
    "coefficients = np.logspace(-2,0,10)\n",
    "fscore = []\n",
    "recall = []\n",
    "precision = []\n",
    "AU = []\n",
    "param_permuations = list(itertools.product(weights, coefficients))\n",
    "for cw,C in param_permuations:\n",
    "    print('Checking class weight {} and coefficient {}'.format(cw, C))\n",
    "    cf,au = train_logistic_regression(data_sc, folds, labels, cw, C)\n",
    "    TP = cf[1][1]\n",
    "    FP = cf[0][1]\n",
    "    FN = cf[1][0]\n",
    "    prec = TP/(TP+FP)\n",
    "    rec = TP/(TP+FN)\n",
    "    f1 = prec*rec*2/(prec+rec)\n",
    "    print('F1 score:', f1)\n",
    "    print('Recall:', rec)\n",
    "    print('Precision:', prec)\n",
    "    print('AUC:', au)\n",
    "    fscore.append(f1)\n",
    "    recall.append(rec)\n",
    "    precision.append(prec)\n",
    "    AU.append(au)\n",
    "\n",
    "idx = np.argmax(AU)\n",
    "best_params = param_permuations[idx]\n",
    "print('Best parameters found for Logistic Regression under AUC metric is {} class weights and {} coefficient'.format(best_params[0], best_params[1]))\n",
    "\n",
    "idx = np.argmax(f1)\n",
    "best_params = param_permuations[idx]\n",
    "print('Best parameters found for Logistic Regression under F1 metric is {} class weights and {} coefficient'.format(best_params[0], best_params[1]))\n",
    "\n",
    "idx = np.argmax(precision)\n",
    "best_params = param_permuations[idx]\n",
    "print('Best parameters found for Logistic Regression under precision metric is {} class weights and {} coefficient'.format(best_params[0], best_params[1]))\n",
    "\n",
    "idx = np.argmax(recall)\n",
    "best_params = param_permuations[idx]\n",
    "print('Best parameters found for Logistic Regression under recall metric is {} class weights and {} coefficient'.format(best_params[0], best_params[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking class weight None and coefficient 0.01\n",
      "Fold 0\n",
      "[[94  0]\n",
      " [18 81]]\n",
      "Area under curve: 0.9758220502901354\n",
      "Fold 1\n",
      "[[94  0]\n",
      " [21 78]]\n",
      "Area under curve: 0.9727057812164195\n",
      "Fold 2\n",
      "[[93  1]\n",
      " [24 74]]\n",
      "Area under curve: 0.9636343899261832\n",
      "Fold 3\n",
      "[[94  0]\n",
      " [19 79]]\n",
      "Area under curve: 0.98762483716891\n",
      "Fold 4\n",
      "[[94  0]\n",
      " [16 82]]\n",
      "Area under curve: 0.9866478506296136\n",
      "Final Confusion Matrix\n",
      "[[93.8  0.2]\n",
      " [19.6 78.8]]\n",
      "F1 score: 0.8883878241262683\n",
      "Recall: 0.8008130081300813\n",
      "Precision: 0.9974683544303797\n",
      "AUC: 0.9772869818462524\n",
      "Checking class weight None and coefficient 0.016681005372000592\n",
      "Fold 0\n",
      "[[94  0]\n",
      " [18 81]]\n",
      "Area under curve: 0.9771115409413282\n",
      "Fold 1\n",
      "[[94  0]\n",
      " [20 79]]\n",
      "Area under curve: 0.9728132387706856\n",
      "Fold 2\n",
      "[[93  1]\n",
      " [23 75]]\n",
      "Area under curve: 0.9663482414242293\n",
      "Fold 3\n",
      "[[94  0]\n",
      " [16 82]]\n",
      "Area under curve: 0.987733391228832\n",
      "Fold 4\n",
      "[[94  0]\n",
      " [15 83]]\n",
      "Area under curve: 0.9867564046895354\n",
      "Final Confusion Matrix\n",
      "[[93.8  0.2]\n",
      " [18.4 80. ]]\n",
      "F1 score: 0.8958566629339305\n",
      "Recall: 0.8130081300813008\n",
      "Precision: 0.997506234413965\n",
      "AUC: 0.9781525634109223\n",
      "Checking class weight None and coefficient 0.027825594022071243\n",
      "Fold 0\n",
      "[[94  0]\n",
      " [15 84]]\n",
      "Area under curve: 0.9787234042553192\n",
      "Fold 1\n",
      "[[94  0]\n",
      " [17 82]]\n",
      "Area under curve: 0.9739952718676124\n",
      "Fold 2\n",
      "[[93  1]\n",
      " [21 77]]\n",
      "Area under curve: 0.9685193226226662\n",
      "Fold 3\n",
      "[[94  0]\n",
      " [12 86]]\n",
      "Area under curve: 0.987733391228832\n",
      "Fold 4\n",
      "[[93  1]\n",
      " [15 83]]\n",
      "Area under curve: 0.9866478506296136\n",
      "Final Confusion Matrix\n",
      "[[93.6  0.4]\n",
      " [16.  82.4]]\n",
      "F1 score: 0.9094922737306843\n",
      "Recall: 0.8373983739837398\n",
      "Precision: 0.9951690821256038\n",
      "AUC: 0.9791238481208087\n",
      "Checking class weight None and coefficient 0.046415888336127774\n",
      "Fold 0\n",
      "[[94  0]\n",
      " [14 85]]\n",
      "Area under curve: 0.9795830646894478\n",
      "Fold 1\n",
      "[[93  1]\n",
      " [17 82]]\n",
      "Area under curve: 0.9747474747474747\n",
      "Fold 2\n",
      "[[93  1]\n",
      " [17 81]]\n",
      "Area under curve: 0.9712331741207122\n",
      "Fold 3\n",
      "[[94  0]\n",
      " [10 88]]\n",
      "Area under curve: 0.987733391228832\n",
      "Fold 4\n",
      "[[93  1]\n",
      " [12 86]]\n",
      "Area under curve: 0.9872991749891447\n",
      "Final Confusion Matrix\n",
      "[[93.4  0.6]\n",
      " [14.  84.4]]\n",
      "F1 score: 0.920392584514722\n",
      "Recall: 0.8577235772357724\n",
      "Precision: 0.9929411764705883\n",
      "AUC: 0.9801192559551222\n",
      "Checking class weight None and coefficient 0.0774263682681127\n",
      "Fold 0\n",
      "[[94  0]\n",
      " [13 86]]\n",
      "Area under curve: 0.9804427251235762\n",
      "Fold 1\n",
      "[[93  1]\n",
      " [16 83]]\n",
      "Area under curve: 0.9749623898560069\n",
      "Fold 2\n",
      "[[93  1]\n",
      " [16 82]]\n",
      "Area under curve: 0.9738384715588362\n",
      "Fold 3\n",
      "[[94  0]\n",
      " [ 9 89]]\n",
      "Area under curve: 0.9871906209292227\n",
      "Fold 4\n",
      "[[93  1]\n",
      " [10 88]]\n",
      "Area under curve: 0.9875162831089882\n",
      "Final Confusion Matrix\n",
      "[[93.4  0.6]\n",
      " [12.8 85.6]]\n",
      "F1 score: 0.9274106175514626\n",
      "Recall: 0.8699186991869919\n",
      "Precision: 0.9930394431554525\n",
      "AUC: 0.980790098115326\n",
      "Checking class weight None and coefficient 0.1291549665014884\n",
      "Fold 0\n",
      "[[93  1]\n",
      " [12 87]]\n",
      "Area under curve: 0.9807650977863743\n",
      "Fold 1\n",
      "[[93  1]\n",
      " [16 83]]\n",
      "Area under curve: 0.975177304964539\n",
      "Fold 2\n",
      "[[93  1]\n",
      " [16 82]]\n",
      "Area under curve: 0.9752496743378203\n",
      "Fold 3\n",
      "[[93  1]\n",
      " [ 9 89]]\n",
      "Area under curve: 0.9868649587494571\n",
      "Fold 4\n",
      "[[93  1]\n",
      " [10 88]]\n",
      "Area under curve: 0.9871906209292227\n",
      "Final Confusion Matrix\n",
      "[[93.   1. ]\n",
      " [12.6 85.8]]\n",
      "F1 score: 0.9265658747300216\n",
      "Recall: 0.8719512195121951\n",
      "Precision: 0.988479262672811\n",
      "AUC: 0.9810495313534828\n",
      "Checking class weight None and coefficient 0.21544346900318834\n",
      "Fold 0\n",
      "[[93  1]\n",
      " [10 89]]\n",
      "Area under curve: 0.9813023855577047\n",
      "Fold 1\n",
      "[[92  2]\n",
      " [13 86]]\n",
      "Area under curve: 0.9745325596389426\n",
      "Fold 2\n",
      "[[93  1]\n",
      " [16 82]]\n",
      "Area under curve: 0.9757924446374293\n",
      "Fold 3\n",
      "[[93  1]\n",
      " [ 9 89]]\n",
      "Area under curve: 0.9868649587494572\n",
      "Fold 4\n",
      "[[92  2]\n",
      " [ 9 89]]\n",
      "Area under curve: 0.9865392965696917\n",
      "Final Confusion Matrix\n",
      "[[92.6  1.4]\n",
      " [11.4 87. ]]\n",
      "F1 score: 0.9314775160599571\n",
      "Recall: 0.8841463414634145\n",
      "Precision: 0.9841628959276018\n",
      "AUC: 0.9810063290306452\n",
      "Checking class weight None and coefficient 0.3593813663804626\n",
      "Fold 0\n",
      "[[93  1]\n",
      " [ 9 90]]\n",
      "Area under curve: 0.9818396733290351\n",
      "Fold 1\n",
      "[[92  2]\n",
      " [12 87]]\n",
      "Area under curve: 0.9753922200730712\n",
      "Fold 2\n",
      "[[93  1]\n",
      " [16 82]]\n",
      "Area under curve: 0.9765523230568823\n",
      "Fold 3\n",
      "[[92  2]\n",
      " [ 9 89]]\n",
      "Area under curve: 0.9866478506296136\n",
      "Fold 4\n",
      "[[92  2]\n",
      " [ 9 89]]\n",
      "Area under curve: 0.9857794181502388\n",
      "Final Confusion Matrix\n",
      "[[92.4  1.6]\n",
      " [11.  87.4]]\n",
      "F1 score: 0.9327641408751334\n",
      "Recall: 0.8882113821138211\n",
      "Precision: 0.9820224719101124\n",
      "AUC: 0.9812422970477682\n",
      "Checking class weight None and coefficient 0.5994842503189409\n",
      "Fold 0\n",
      "[[93  1]\n",
      " [ 8 91]]\n",
      "Area under curve: 0.9821620459918333\n",
      "Fold 1\n",
      "[[91  3]\n",
      " [10 89]]\n",
      "Area under curve: 0.9745325596389426\n",
      "Fold 2\n",
      "[[93  1]\n",
      " [14 84]]\n",
      "Area under curve: 0.9764437689969605\n",
      "Fold 3\n",
      "[[92  2]\n",
      " [ 9 89]]\n",
      "Area under curve: 0.9859965262700825\n",
      "Fold 4\n",
      "[[91  3]\n",
      " [ 9 89]]\n",
      "Area under curve: 0.9851280937907078\n",
      "Final Confusion Matrix\n",
      "[[92.   2. ]\n",
      " [10.  88.4]]\n",
      "F1 score: 0.9364406779661018\n",
      "Recall: 0.8983739837398375\n",
      "Precision: 0.9778761061946902\n",
      "AUC: 0.9808525989377055\n",
      "Checking class weight None and coefficient 1.0\n",
      "Fold 0\n",
      "[[93  1]\n",
      " [ 6 93]]\n",
      "Area under curve: 0.9824844186546315\n",
      "Fold 1\n",
      "[[91  3]\n",
      " [10 89]]\n",
      "Area under curve: 0.9737803567590801\n",
      "Fold 2\n",
      "[[93  1]\n",
      " [14 84]]\n",
      "Area under curve: 0.9764437689969605\n",
      "Fold 3\n",
      "[[92  2]\n",
      " [ 7 91]]\n",
      "Area under curve: 0.9861050803300043\n",
      "Fold 4\n",
      "[[90  4]\n",
      " [ 8 90]]\n",
      "Area under curve: 0.9837168910117238\n",
      "Final Confusion Matrix\n",
      "[[91.8  2.2]\n",
      " [ 9.  89.4]]\n",
      "F1 score: 0.9410526315789475\n",
      "Recall: 0.9085365853658537\n",
      "Precision: 0.9759825327510917\n",
      "AUC: 0.9805061031504799\n",
      "Checking class weight balanced and coefficient 0.01\n",
      "Fold 0\n",
      "[[94  0]\n",
      " [18 81]]\n",
      "Area under curve: 0.9754996776273372\n",
      "Fold 1\n",
      "[[94  0]\n",
      " [21 78]]\n",
      "Area under curve: 0.9727057812164195\n",
      "Fold 2\n",
      "[[93  1]\n",
      " [24 74]]\n",
      "Area under curve: 0.9632001736864959\n",
      "Fold 3\n",
      "[[94  0]\n",
      " [19 79]]\n",
      "Area under curve: 0.987733391228832\n",
      "Fold 4\n",
      "[[94  0]\n",
      " [16 82]]\n",
      "Area under curve: 0.9866478506296136\n",
      "Final Confusion Matrix\n",
      "[[93.8  0.2]\n",
      " [19.6 78.8]]\n",
      "F1 score: 0.8883878241262683\n",
      "Recall: 0.8008130081300813\n",
      "Precision: 0.9974683544303797\n",
      "AUC: 0.9771573748777396\n",
      "Checking class weight balanced and coefficient 0.016681005372000592\n",
      "Fold 0\n",
      "[[94  0]\n",
      " [18 81]]\n",
      "Area under curve: 0.9770040833870621\n",
      "Fold 1\n",
      "[[94  0]\n",
      " [20 79]]\n",
      "Area under curve: 0.9728132387706856\n",
      "Fold 2\n",
      "[[93  1]\n",
      " [23 75]]\n",
      "Area under curve: 0.9662396873643073\n",
      "Fold 3\n",
      "[[94  0]\n",
      " [18 80]]\n",
      "Area under curve: 0.9878419452887539\n",
      "Fold 4\n",
      "[[94  0]\n",
      " [15 83]]\n",
      "Area under curve: 0.9866478506296135\n",
      "Final Confusion Matrix\n",
      "[[93.8  0.2]\n",
      " [18.8 79.6]]\n",
      "F1 score: 0.8933782267115601\n",
      "Recall: 0.8089430894308943\n",
      "Precision: 0.9974937343358395\n",
      "AUC: 0.9781093610880844\n",
      "Checking class weight balanced and coefficient 0.027825594022071243\n",
      "Fold 0\n",
      "[[94  0]\n",
      " [16 83]]\n",
      "Area under curve: 0.9787234042553192\n",
      "Fold 1\n",
      "[[94  0]\n",
      " [18 81]]\n",
      "Area under curve: 0.9741027294218784\n",
      "Fold 2\n",
      "[[93  1]\n",
      " [21 77]]\n",
      "Area under curve: 0.9685193226226662\n",
      "Fold 3\n",
      "[[94  0]\n",
      " [12 86]]\n",
      "Area under curve: 0.987733391228832\n",
      "Fold 4\n",
      "[[94  0]\n",
      " [15 83]]\n",
      "Area under curve: 0.9865392965696917\n",
      "Final Confusion Matrix\n",
      "[[93.8  0.2]\n",
      " [16.4 82. ]]\n",
      "F1 score: 0.9080841638981173\n",
      "Recall: 0.8333333333333333\n",
      "Precision: 0.9975669099756691\n",
      "AUC: 0.9791236288196774\n",
      "Checking class weight balanced and coefficient 0.046415888336127774\n",
      "Fold 0\n",
      "[[94  0]\n",
      " [15 84]]\n",
      "Area under curve: 0.9795830646894478\n",
      "Fold 1\n",
      "[[93  1]\n",
      " [17 82]]\n",
      "Area under curve: 0.9747474747474747\n",
      "Fold 2\n",
      "[[93  1]\n",
      " [19 79]]\n",
      "Area under curve: 0.9712331741207122\n",
      "Fold 3\n",
      "[[94  0]\n",
      " [10 88]]\n",
      "Area under curve: 0.987733391228832\n",
      "Fold 4\n",
      "[[93  1]\n",
      " [12 86]]\n",
      "Area under curve: 0.9872991749891447\n",
      "Final Confusion Matrix\n",
      "[[93.4  0.6]\n",
      " [14.6 83.8]]\n",
      "F1 score: 0.9168490153172868\n",
      "Recall: 0.8516260162601627\n",
      "Precision: 0.9928909952606636\n",
      "AUC: 0.9801192559551222\n",
      "Checking class weight balanced and coefficient 0.0774263682681127\n",
      "Fold 0\n",
      "[[94  0]\n",
      " [13 86]]\n",
      "Area under curve: 0.9803352675693101\n",
      "Fold 1\n",
      "[[93  1]\n",
      " [16 83]]\n",
      "Area under curve: 0.9749623898560069\n",
      "Fold 2\n",
      "[[93  1]\n",
      " [16 82]]\n",
      "Area under curve: 0.9738384715588362\n",
      "Fold 3\n",
      "[[94  0]\n",
      " [ 9 89]]\n",
      "Area under curve: 0.9871906209292227\n",
      "Fold 4\n",
      "[[93  1]\n",
      " [10 88]]\n",
      "Area under curve: 0.9874077290490664\n",
      "Final Confusion Matrix\n",
      "[[93.4  0.6]\n",
      " [12.8 85.6]]\n",
      "F1 score: 0.9274106175514626\n",
      "Recall: 0.8699186991869919\n",
      "Precision: 0.9930394431554525\n",
      "AUC: 0.9807468957924884\n",
      "Checking class weight balanced and coefficient 0.1291549665014884\n",
      "Fold 0\n",
      "[[93  1]\n",
      " [12 87]]\n",
      "Area under curve: 0.9807650977863744\n",
      "Fold 1\n",
      "[[93  1]\n",
      " [16 83]]\n",
      "Area under curve: 0.9753922200730711\n",
      "Fold 2\n",
      "[[93  1]\n",
      " [16 82]]\n",
      "Area under curve: 0.9752496743378203\n",
      "Fold 3\n",
      "[[93  1]\n",
      " [ 9 89]]\n",
      "Area under curve: 0.9868649587494571\n",
      "Fold 4\n",
      "[[93  1]\n",
      " [10 88]]\n",
      "Area under curve: 0.9874077290490664\n",
      "Final Confusion Matrix\n",
      "[[93.   1. ]\n",
      " [12.6 85.8]]\n",
      "F1 score: 0.9265658747300216\n",
      "Recall: 0.8719512195121951\n",
      "Precision: 0.988479262672811\n",
      "AUC: 0.9811359359991579\n",
      "Checking class weight balanced and coefficient 0.21544346900318834\n",
      "Fold 0\n",
      "[[93  1]\n",
      " [10 89]]\n",
      "Area under curve: 0.9813023855577047\n",
      "Fold 1\n",
      "[[92  2]\n",
      " [13 86]]\n",
      "Area under curve: 0.9747474747474748\n",
      "Fold 2\n",
      "[[93  1]\n",
      " [16 82]]\n",
      "Area under curve: 0.9760095527572732\n",
      "Fold 3\n",
      "[[93  1]\n",
      " [ 9 89]]\n",
      "Area under curve: 0.9868649587494572\n",
      "Fold 4\n",
      "[[92  2]\n",
      " [ 9 89]]\n",
      "Area under curve: 0.9865392965696917\n",
      "Final Confusion Matrix\n",
      "[[92.6  1.4]\n",
      " [11.4 87. ]]\n",
      "F1 score: 0.9314775160599571\n",
      "Recall: 0.8841463414634145\n",
      "Precision: 0.9841628959276018\n",
      "AUC: 0.9810927336763203\n",
      "Checking class weight balanced and coefficient 0.3593813663804626\n",
      "Fold 0\n",
      "[[93  1]\n",
      " [10 89]]\n",
      "Area under curve: 0.981839673329035\n",
      "Fold 1\n",
      "[[92  2]\n",
      " [12 87]]\n",
      "Area under curve: 0.9753922200730712\n",
      "Fold 2\n",
      "[[93  1]\n",
      " [16 82]]\n",
      "Area under curve: 0.9764437689969605\n",
      "Fold 3\n",
      "[[92  2]\n",
      " [ 9 89]]\n",
      "Area under curve: 0.9867564046895354\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4\n",
      "[[92  2]\n",
      " [ 9 89]]\n",
      "Area under curve: 0.9857794181502388\n",
      "Final Confusion Matrix\n",
      "[[92.4  1.6]\n",
      " [11.2 87.2]]\n",
      "F1 score: 0.9316239316239316\n",
      "Recall: 0.8861788617886178\n",
      "Precision: 0.981981981981982\n",
      "AUC: 0.9812422970477682\n",
      "Checking class weight balanced and coefficient 0.5994842503189409\n",
      "Fold 0\n",
      "[[93  1]\n",
      " [ 8 91]]\n",
      "Area under curve: 0.9821620459918333\n",
      "Fold 1\n",
      "[[91  3]\n",
      " [10 89]]\n",
      "Area under curve: 0.9745325596389426\n",
      "Fold 2\n",
      "[[93  1]\n",
      " [16 82]]\n",
      "Area under curve: 0.9762266608771168\n",
      "Fold 3\n",
      "[[92  2]\n",
      " [ 9 89]]\n",
      "Area under curve: 0.9862136343899263\n",
      "Fold 4\n",
      "[[91  3]\n",
      " [ 9 89]]\n",
      "Area under curve: 0.9853452019105514\n",
      "Final Confusion Matrix\n",
      "[[92.   2. ]\n",
      " [10.4 88. ]]\n",
      "F1 score: 0.9341825902335457\n",
      "Recall: 0.8943089430894309\n",
      "Precision: 0.9777777777777777\n",
      "AUC: 0.980896020561674\n",
      "Checking class weight balanced and coefficient 1.0\n",
      "Fold 0\n",
      "[[93  1]\n",
      " [ 7 92]]\n",
      "Area under curve: 0.9824844186546315\n",
      "Fold 1\n",
      "[[91  3]\n",
      " [10 89]]\n",
      "Area under curve: 0.9737803567590801\n",
      "Fold 2\n",
      "[[93  1]\n",
      " [14 84]]\n",
      "Area under curve: 0.9761181068171949\n",
      "Fold 3\n",
      "[[92  2]\n",
      " [ 7 91]]\n",
      "Area under curve: 0.9861050803300043\n",
      "Fold 4\n",
      "[[90  4]\n",
      " [ 9 89]]\n",
      "Area under curve: 0.9837168910117238\n",
      "Final Confusion Matrix\n",
      "[[91.8  2.2]\n",
      " [ 9.4 89. ]]\n",
      "F1 score: 0.9388185654008437\n",
      "Recall: 0.9044715447154471\n",
      "Precision: 0.9758771929824561\n",
      "AUC: 0.9804409707145268\n",
      "Best parameters found for Logistic Regression under AUC metric is None class weights and 0.3593813663804626 coefficient\n",
      "Best parameters found for Logistic Regression under F1 metric is None class weights and 0.01 coefficient\n",
      "Best parameters found for Logistic Regression under precision metric is balanced class weights and 0.027825594022071243 coefficient\n",
      "Best parameters found for Logistic Regression under recall metric is None class weights and 1.0 coefficient\n"
     ]
    }
   ],
   "source": [
    "#Notice that if we fully downsample the dataset so that valid and fraud are equally represented, we have much more consistent metrics.\n",
    "#Then we see that the recommended parameters begin to converge.\n",
    "\n",
    "csv_data2 = [row for row in csv_data if int(row[-1]) == 1 or random.random() < 0.00164/.05]\n",
    "\n",
    "# Format: Time, V1, ..., V28, Amount, Class\n",
    "data2 = np.array([[float(x) for x in row[1:-1]] for row in csv_data2])\n",
    "times2 = np.array([float(row[0]) for row in csv_data2])\n",
    "labels2 = np.array([int(row[-1]) for row in csv_data2])\n",
    "\n",
    "data_sc2 = scaler.fit_transform(data2)\n",
    "\n",
    "fraud_indices2 = np.where(labels2 == 1)[0]\n",
    "np.random.shuffle(fraud_indices2)\n",
    "fraud_splits2 = np.array_split(fraud_indices2, 5)\n",
    "\n",
    "valid_indices2 = np.where(labels2 == 0)[0]\n",
    "np.random.shuffle(valid_indices2)\n",
    "valid_splits2 = np.array_split(valid_indices2, 5)\n",
    "\n",
    "folds2 = [np.concatenate((fraud_sp, valid_sp)) for fraud_sp, valid_sp in zip(fraud_splits2, valid_splits2)]\n",
    "\n",
    "weights = [None,'balanced']\n",
    "coefficients = np.logspace(-2,0,10)\n",
    "fscore = []\n",
    "recall = []\n",
    "precision = []\n",
    "AU = []\n",
    "param_permuations = list(itertools.product(weights, coefficients))\n",
    "for cw,C in param_permuations:\n",
    "    print('Checking class weight {} and coefficient {}'.format(cw, C))\n",
    "    cf,au = train_logistic_regression(data_sc2, folds2, labels2, cw, C)\n",
    "    TP = cf[1][1]\n",
    "    FP = cf[0][1]\n",
    "    FN = cf[1][0]\n",
    "    prec = TP/(TP+FP)\n",
    "    rec = TP/(TP+FN)\n",
    "    f1 = prec*rec*2/(prec+rec)\n",
    "    print('F1 score:', f1)\n",
    "    print('Recall:', rec)\n",
    "    print('Precision:', prec)\n",
    "    print('AUC:', au)\n",
    "    fscore.append(f1)\n",
    "    recall.append(rec)\n",
    "    precision.append(prec)\n",
    "    AU.append(au)\n",
    "\n",
    "idx = np.argmax(AU)\n",
    "best_params = param_permuations[idx]\n",
    "print('Best parameters found for Logistic Regression under AUC metric is {} class weights and {} coefficient'.format(best_params[0], best_params[1]))\n",
    "\n",
    "idx = np.argmax(f1)\n",
    "best_params = param_permuations[idx]\n",
    "print('Best parameters found for Logistic Regression under F1 metric is {} class weights and {} coefficient'.format(best_params[0], best_params[1]))\n",
    "\n",
    "idx = np.argmax(precision)\n",
    "best_params = param_permuations[idx]\n",
    "print('Best parameters found for Logistic Regression under precision metric is {} class weights and {} coefficient'.format(best_params[0], best_params[1]))\n",
    "\n",
    "idx = np.argmax(recall)\n",
    "best_params = param_permuations[idx]\n",
    "print('Best parameters found for Logistic Regression under recall metric is {} class weights and {} coefficient'.format(best_params[0], best_params[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_KNN(data, k, scale=False):\n",
    "    confusion_mat = np.zeros((2, 2))\n",
    "    for i in range(5):\n",
    "        knn = KNeighborsClassifier(n_neighbors=k)\n",
    "        \n",
    "        train_data = np.delete(data, folds[i], axis=0)\n",
    "        test_data = data[folds[i]]\n",
    "        if scale:\n",
    "            scaler = StandardScaler()\n",
    "            train_data = scaler.fit_transform(train_data)\n",
    "            test_data = scaler.transform(test_data)\n",
    "\n",
    "        knn.fit(train_data, np.delete(labels, folds[i]))\n",
    "        pred = knn.predict(test_data)\n",
    "\n",
    "        conf_mat = confusion_matrix(labels[folds[i]], pred)\n",
    "        print('Fold', i)\n",
    "        print(conf_mat)\n",
    "\n",
    "        confusion_mat += conf_mat\n",
    "\n",
    "    confusion_mat /= 5\n",
    "    print('Final Confusion Matrix')\n",
    "    print(confusion_mat)\n",
    "    print('False negatives (valid):', confusion_mat[0, 1] / sum(confusion_mat[0, :]))\n",
    "    print('False positives (fraud):', confusion_mat[1, 0] / sum(confusion_mat[1,:]))\n",
    "    return confusion_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0\n",
      "[[2869    3]\n",
      " [  26   73]]\n",
      "Fold 1\n",
      "[[2870    2]\n",
      " [  33   66]]\n",
      "Fold 2\n",
      "[[2870    2]\n",
      " [  27   71]]\n",
      "Fold 3\n",
      "[[2871    0]\n",
      " [  29   69]]\n",
      "Fold 4\n",
      "[[2870    1]\n",
      " [  25   73]]\n",
      "Final Confusion Matrix\n",
      "[[2.87e+03 1.60e+00]\n",
      " [2.80e+01 7.04e+01]]\n",
      "False negatives (valid): 0.0005571806658308957\n",
      "False positives (fraud): 0.2845528455284553\n",
      "Confusion Matrix:\n",
      "[[2.87e+03 1.60e+00]\n",
      " [2.80e+01 7.04e+01]]\n",
      "\n",
      "Fold 0\n",
      "[[2869    3]\n",
      " [  28   71]]\n",
      "Fold 1\n",
      "[[2870    2]\n",
      " [  33   66]]\n",
      "Fold 2\n",
      "[[2870    2]\n",
      " [  33   65]]\n",
      "Fold 3\n",
      "[[2871    0]\n",
      " [  32   66]]\n",
      "Fold 4\n",
      "[[2870    1]\n",
      " [  26   72]]\n",
      "Final Confusion Matrix\n",
      "[[2.87e+03 1.60e+00]\n",
      " [3.04e+01 6.80e+01]]\n",
      "False negatives (valid): 0.0005571806658308957\n",
      "False positives (fraud): 0.30894308943089427\n",
      "Confusion Matrix:\n",
      "[[2.87e+03 1.60e+00]\n",
      " [3.04e+01 6.80e+01]]\n",
      "\n",
      "Fold 0\n",
      "[[2869    3]\n",
      " [  28   71]]\n",
      "Fold 1\n",
      "[[2870    2]\n",
      " [  34   65]]\n",
      "Fold 2\n",
      "[[2870    2]\n",
      " [  37   61]]\n",
      "Fold 3\n",
      "[[2871    0]\n",
      " [  36   62]]\n",
      "Fold 4\n",
      "[[2870    1]\n",
      " [  27   71]]\n",
      "Final Confusion Matrix\n",
      "[[2.87e+03 1.60e+00]\n",
      " [3.24e+01 6.60e+01]]\n",
      "False negatives (valid): 0.0005571806658308957\n",
      "False positives (fraud): 0.3292682926829268\n",
      "Confusion Matrix:\n",
      "[[2.87e+03 1.60e+00]\n",
      " [3.24e+01 6.60e+01]]\n",
      "\n",
      "Fold 0\n",
      "[[2870    2]\n",
      " [  30   69]]\n",
      "Fold 1\n",
      "[[2870    2]\n",
      " [  35   64]]\n",
      "Fold 2\n",
      "[[2870    2]\n",
      " [  40   58]]\n",
      "Fold 3\n",
      "[[2871    0]\n",
      " [  41   57]]\n",
      "Fold 4\n",
      "[[2870    1]\n",
      " [  29   69]]\n",
      "Final Confusion Matrix\n",
      "[[2.8702e+03 1.4000e+00]\n",
      " [3.5000e+01 6.3400e+01]]\n",
      "False negatives (valid): 0.0004875330826020337\n",
      "False positives (fraud): 0.35569105691056907\n",
      "Confusion Matrix:\n",
      "[[2.8702e+03 1.4000e+00]\n",
      " [3.5000e+01 6.3400e+01]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for k in [5, 7, 9, 11]:\n",
    "    conf = train_KNN(data, k)\n",
    "    print('Confusion Matrix:')\n",
    "    print(conf)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
