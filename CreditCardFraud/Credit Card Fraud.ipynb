{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import itertools\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# import warnings\n",
    "# warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the data\n",
    "\n",
    "Note about the data: The dataset is rather large, and very skewed toward valid transactions. To balance it a bit better, we sample and only keep around 5% of the valid transactions (the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data is imbalanced, with 14753 samples in total but only 492 cases of fraud\n"
     ]
    }
   ],
   "source": [
    "with open('creditcard.csv', newline='') as f:\n",
    "    reader = csv.reader(f, delimiter=',')\n",
    "    csv_data = list(reader)[1:]\n",
    "    \n",
    "csv_data = [row for row in csv_data if int(row[-1]) == 1 or random.random() < .05]\n",
    "\n",
    "# Format: Time, V1, ..., V28, Amount, Class\n",
    "data = np.array([[float(x) for x in row[1:-1]] for row in csv_data])\n",
    "times = np.array([float(row[0]) for row in csv_data])\n",
    "labels = np.array([int(row[-1]) for row in csv_data])\n",
    "print('The data is imbalanced, with {} samples in total but only {} cases of fraud'.format(len(labels), sum(labels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.71509701e-01  1.14883613e-01 -2.23337111e-01  1.46039243e-01\n",
      " -8.86846563e-02 -4.14206014e-02 -1.70273613e-01  1.63854599e-02\n",
      " -9.61740652e-02 -1.75920588e-01  1.17219737e-01 -2.06876287e-01\n",
      " -1.32585958e-03 -2.33277979e-01 -6.26666722e-03 -1.26621898e-01\n",
      " -2.06083862e-01 -7.59872808e-02  2.51322178e-02  2.70150806e-02\n",
      "  2.48735349e-02  1.01485880e-02  5.33243455e-04 -8.32212611e-03\n",
      " -3.48668130e-03  9.30346487e-04  3.47527085e-03  4.10286201e-03\n",
      "  9.15060089e+01]\n",
      "[5.70120561e+00 3.47311615e+00 5.36177891e+00 2.86088412e+00\n",
      " 3.01021483e+00 1.89777117e+00 4.01349245e+00 3.01027852e+00\n",
      " 1.56588721e+00 2.93166759e+00 1.68906618e+00 2.87788205e+00\n",
      " 1.00048107e+00 2.97624829e+00 8.45542440e-01 1.74409195e+00\n",
      " 3.62694073e+00 1.11852630e+00 7.38510811e-01 5.77811922e-01\n",
      " 1.02907114e+00 5.91302042e-01 4.62185951e-01 3.66085204e-01\n",
      " 2.81665897e-01 2.28227666e-01 2.03689041e-01 9.93289080e-02\n",
      " 6.11538809e+04]\n",
      "The PCA features have mean 0 but different variances\n",
      "The transaction amount is not scaled. We should scale it so it does not affect the SVM too much\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(data, axis=0))\n",
    "print(np.var(data, axis=0))\n",
    "print('The PCA features have mean 0 but different variances')\n",
    "print('The transaction amount is not scaled. We should scale it so it does not affect the SVM too much')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-5.54603547e-17  3.79566386e-16  3.34842903e-16  1.24575557e-16\n",
      " -2.46975332e-16  4.98294703e-17 -1.01245766e-15  6.87690338e-17\n",
      "  1.19473332e-16 -3.45182810e-16 -4.47968556e-16 -1.02306002e-16\n",
      "  2.00431641e-16 -3.03631285e-17  9.98229945e-16  2.23245848e-16\n",
      " -9.50241377e-16  8.75430383e-17 -2.64292230e-17  2.42694317e-18\n",
      " -2.26270120e-17 -1.30050289e-16 -1.31517273e-16  2.37351279e-17\n",
      "  1.10427795e-16  8.54585011e-17 -1.83245497e-16 -7.72379366e-17\n",
      "  8.24251796e-15]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "data_sc = scaler.fit_transform(data)\n",
    "print(np.mean(data_sc, axis=0))\n",
    "print(np.var(data_sc, axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preliminary plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.09552461  1.03837033 -0.29124116 -0.3437115  -0.59193265  0.69350299\n",
      " -0.43321149  1.32177832 -0.91359973]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the first two principal components\n",
    "data_fraud = data[np.where(labels == 1)]\n",
    "data_valid = data[np.where(labels == 0)]\n",
    "plt.scatter(data_valid[:, 0], data_valid[:, -1], c='b')\n",
    "plt.scatter(data_fraud[:, 0], data_fraud[:, -1], c='r')\n",
    "print(data_valid[1:10, 0])\n",
    "plt.ylim((0, 10000))\n",
    "plt.legend(['valid', 'fraud'])\n",
    "plt.xlabel('First PCA feature')\n",
    "plt.ylabel('Transaction amount')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraud_indices = np.where(labels == 1)[0]\n",
    "np.random.shuffle(fraud_indices)\n",
    "fraud_splits = np.array_split(fraud_indices, 5)\n",
    "\n",
    "valid_indices = np.where(labels == 0)[0]\n",
    "np.random.shuffle(valid_indices)\n",
    "valid_splits = np.array_split(valid_indices, 5)\n",
    "\n",
    "folds = [np.concatenate((fraud_sp, valid_sp)) for fraud_sp, valid_sp in zip(fraud_splits, valid_splits)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_binary_SVM(data, scale=False, kernel=None, class_weight=None):\n",
    "    confusion_mat = np.zeros((2, 2))\n",
    "    for i in range(5):\n",
    "        if kernel is None:\n",
    "            if class_weight is None:\n",
    "                svm = LinearSVC(fit_intercept=False, dual=False)\n",
    "            else:\n",
    "                svm = LinearSVC(fit_intercept=False, dual=False, class_weight=class_weight)\n",
    "        else:\n",
    "            if class_weight is None:\n",
    "                svm = SVC(kernel=kernel, gamma='auto')\n",
    "            else:\n",
    "                svm = SVC(kernel=kernel, gamma='auto', class_weight=class_weight)\n",
    "        \n",
    "        train_data = np.delete(data, folds[i], axis=0)\n",
    "        test_data = data[folds[i]]\n",
    "        if scale:\n",
    "            scaler = StandardScaler()\n",
    "            train_data = scaler.fit_transform(train_data)\n",
    "            test_data = scaler.transform(test_data)\n",
    "\n",
    "        svm.fit(train_data, np.delete(labels, folds[i]))\n",
    "        pred = svm.predict(test_data)\n",
    "\n",
    "        conf_mat = confusion_matrix(labels[folds[i]], pred)\n",
    "        print('Fold', i)\n",
    "        print(conf_mat)\n",
    "\n",
    "        confusion_mat += conf_mat\n",
    "\n",
    "    confusion_mat /= 5\n",
    "    print('Final Confusion Matrix')\n",
    "    print(confusion_mat)\n",
    "    print('False negatives (valid):', confusion_mat[0, 1] / sum(confusion_mat[0, :]))\n",
    "    print('False positives (fraud):', confusion_mat[1, 0] / sum(confusion_mat[1,:]))\n",
    "    return confusion_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear SVM -- Without scaling or class weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0\n",
      "[[2848    5]\n",
      " [  19   80]]\n",
      "Fold 1\n",
      "[[2845    7]\n",
      " [  23   76]]\n",
      "Fold 2\n",
      "[[2844    8]\n",
      " [  23   75]]\n",
      "Fold 3\n",
      "[[2839   13]\n",
      " [  17   81]]\n",
      "Fold 4\n",
      "[[2843    9]\n",
      " [  22   76]]\n",
      "Final Confusion Matrix\n",
      "[[2843.8    8.4]\n",
      " [  20.8   77.6]]\n",
      "False negatives (valid): 0.0029450950143748685\n",
      "False positives (fraud): 0.21138211382113822\n"
     ]
    }
   ],
   "source": [
    "train_binary_SVM(data);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear SVM with Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0\n",
      "[[2849    4]\n",
      " [  17   82]]\n",
      "Fold 1\n",
      "[[2841   11]\n",
      " [  19   80]]\n",
      "Fold 2\n",
      "[[2843    9]\n",
      " [  15   83]]\n",
      "Fold 3\n",
      "[[2848    4]\n",
      " [  15   83]]\n",
      "Fold 4\n",
      "[[2840   12]\n",
      " [  16   82]]\n",
      "Final Confusion Matrix\n",
      "[[2844.2    8. ]\n",
      " [  16.4   82. ]]\n",
      "False negatives (valid): 0.002804852394642732\n",
      "False positives (fraud): 0.16666666666666663\n"
     ]
    }
   ],
   "source": [
    "train_binary_SVM(data, scale=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear SVM with Scaling and Class Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0\n",
      "[[2754   99]\n",
      " [   9   90]]\n",
      "Fold 1\n",
      "[[2731  121]\n",
      " [  11   88]]\n",
      "Fold 2\n",
      "[[2712  140]\n",
      " [   8   90]]\n",
      "Fold 3\n",
      "[[2750  102]\n",
      " [   5   93]]\n",
      "Fold 4\n",
      "[[2695  157]\n",
      " [   5   93]]\n",
      "Final Confusion Matrix\n",
      "[[2728.4  123.8]\n",
      " [   7.6   90.8]]\n",
      "False negatives (valid): 0.04340509080709627\n",
      "False positives (fraud): 0.07723577235772358\n"
     ]
    }
   ],
   "source": [
    "train_binary_SVM(data, scale=True, class_weight='balanced');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kernel SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RBF Kernel with Scaling and Class Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0\n",
      "[[2853    0]\n",
      " [  19   80]]\n",
      "Fold 1\n",
      "[[2849    3]\n",
      " [  22   77]]\n",
      "Fold 2\n",
      "[[2852    0]\n",
      " [  23   75]]\n",
      "Fold 3\n",
      "[[2849    3]\n",
      " [  19   79]]\n",
      "Fold 4\n",
      "[[2849    3]\n",
      " [  23   75]]\n",
      "Final Confusion Matrix\n",
      "[[2.8504e+03 1.8000e+00]\n",
      " [2.1200e+01 7.7200e+01]]\n",
      "False negatives (valid): 0.0006310917887946147\n",
      "False positives (fraud): 0.2154471544715447\n"
     ]
    }
   ],
   "source": [
    "train_binary_SVM(data, scale=True, kernel='rbf');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0\n",
      "[[2843   10]\n",
      " [  43   56]]\n",
      "Fold 1\n",
      "[[2842   10]\n",
      " [  42   57]]\n",
      "Fold 2\n",
      "[[2837   15]\n",
      " [  51   47]]\n",
      "Fold 3\n",
      "[[2841   11]\n",
      " [  49   49]]\n",
      "Fold 4\n",
      "[[2841   11]\n",
      " [  50   48]]\n",
      "Final Confusion Matrix\n",
      "[[2840.8   11.4]\n",
      " [  47.    51.4]]\n",
      "False negatives (valid): 0.003996914662365893\n",
      "False positives (fraud): 0.4776422764227642\n"
     ]
    }
   ],
   "source": [
    "train_binary_SVM(data, kernel='rbf', class_weight='balanced');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Polynomial Kernel with Scaling and Class Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0\n",
      "[[2851    2]\n",
      " [  18   81]]\n",
      "Fold 1\n",
      "[[2850    2]\n",
      " [  19   80]]\n",
      "Fold 2\n",
      "[[2850    2]\n",
      " [  17   81]]\n",
      "Fold 3\n",
      "[[2846    6]\n",
      " [  21   77]]\n",
      "Fold 4\n",
      "[[2843    9]\n",
      " [  18   80]]\n",
      "Final Confusion Matrix\n",
      "[[2848.     4.2]\n",
      " [  18.6   79.8]]\n",
      "False negatives (valid): 0.0014725475071874345\n",
      "False positives (fraud): 0.18902439024390244\n"
     ]
    }
   ],
   "source": [
    "train_binary_SVM(data, scale=True, kernel='poly');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0\n",
      "[[2849    4]\n",
      " [  15   84]]\n",
      "Fold 1\n",
      "[[2823   29]\n",
      " [  18   81]]\n",
      "Fold 2\n",
      "[[2833   19]\n",
      " [  13   85]]\n",
      "Fold 3\n",
      "[[2832   20]\n",
      " [  13   85]]\n",
      "Fold 4\n",
      "[[2823   29]\n",
      " [   9   89]]\n",
      "Final Confusion Matrix\n",
      "[[2832.    20.2]\n",
      " [  13.6   84.8]]\n",
      "False negatives (valid): 0.007082252296472898\n",
      "False positives (fraud): 0.13821138211382114\n"
     ]
    }
   ],
   "source": [
    "train_binary_SVM(data, scale=True, kernel='poly', class_weight='balanced');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_logistic_regression(data, class_weight = None, C=1.0):\n",
    "    err = 0\n",
    "    err_valid = 0\n",
    "    err_fraud = 0\n",
    "    confusion_mat = np.zeros((2, 2))\n",
    "    AU = 0\n",
    "    for i in range(5):\n",
    "        model = LogisticRegression(class_weight=class_weight, C=C)\n",
    "        \n",
    "        model.fit(np.delete(data, folds[i], axis=0), np.delete(labels, folds[i]))\n",
    "        pred = model.predict(data[folds[i]])\n",
    "        pred1 = model.predict_proba(data[folds[i]])[:,1]\n",
    "        #err_fold = np.sum((pred - labels[folds[i]])**2) / len(folds[i])\n",
    "        #pred_valid = model.predict(data[valid_splits[i]])\n",
    "        #err_valid_fold = np.sum((pred_valid - labels[valid_splits[i]])**2) / len(valid_splits[i])\n",
    "        #pred_fraud = model.predict(data[fraud_splits[i]])\n",
    "        #err_fraud_fold = np.sum((pred_fraud - labels[fraud_splits[i]])**2) / len(fraud_splits[i])\n",
    "        #print('Fold', i, 'Error:', err_fold, 'Valid Error:', err_valid_fold, 'Fraud Error', err_fraud_fold)\n",
    "        #err += err_fold\n",
    "        #err_valid += err_valid_fold\n",
    "        #err_fraud += err_fraud_fold\n",
    "        conf_mat = confusion_matrix(labels[folds[i]], pred)\n",
    "        fpr, tpr, thresholds = roc_curve(labels[folds[i]], pred1)\n",
    "        area_under_curve = auc(fpr, tpr)\n",
    "        AU += area_under_curve\n",
    "        print('Fold', i)\n",
    "        print(conf_mat)\n",
    "        print('Area under curve:', area_under_curve)\n",
    "\n",
    "        confusion_mat += conf_mat\n",
    "    AU/=5\n",
    "    confusion_mat /= 5\n",
    "    print('Final Confusion Matrix')\n",
    "    print(confusion_mat)\n",
    "    return confusion_mat, AU\n",
    "    #err /= 5\n",
    "    #err_valid /= 5\n",
    "    #err_fraud /= 5\n",
    "    #print('FINAL Error:', err, 'Valid Error:', err_valid, 'Fraud Error', err_fraud)\n",
    "    #return err, err_valid, err_fraud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression with Scaling, Class Weights, and Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking class weight None and coefficient 0.01\n",
      "Fold 0\n",
      "[[2852    1]\n",
      " [  19   80]]\n",
      "Area under curve: 0.9805839679656714\n",
      "Fold 1\n",
      "[[2848    4]\n",
      " [  19   80]]\n",
      "Area under curve: 0.9623974669556717\n",
      "Fold 2\n",
      "[[2852    0]\n",
      " [  18   80]]\n",
      "Area under curve: 0.9824970661476372\n",
      "Fold 3\n",
      "[[2849    3]\n",
      " [  15   83]]\n",
      "Area under curve: 0.9830087013767639\n",
      "Fold 4\n",
      "[[2848    4]\n",
      " [  19   79]]\n",
      "Area under curve: 0.9922682256633367\n",
      "Final Confusion Matrix\n",
      "[[2.8498e+03 2.4000e+00]\n",
      " [1.8000e+01 8.0400e+01]]\n",
      "F1 score: 0.8874172185430463\n",
      "Recall: 0.8170731707317074\n",
      "Precision: 0.9710144927536232\n",
      "AUC: 0.9801510856218162\n",
      "Checking class weight None and coefficient 0.016681005372000592\n",
      "Fold 0\n",
      "[[2852    1]\n",
      " [  19   80]]\n",
      "Area under curve: 0.978796021908535\n",
      "Fold 1\n",
      "[[2848    4]\n",
      " [  19   80]]\n",
      "Area under curve: 0.9636229050675055\n",
      "Fold 2\n",
      "[[2852    0]\n",
      " [  16   82]]\n",
      "Area under curve: 0.983126771045024\n",
      "Fold 3\n",
      "[[2849    3]\n",
      " [  15   83]]\n",
      "Area under curve: 0.9830265907204395\n",
      "Fold 4\n",
      "[[2847    5]\n",
      " [  19   79]]\n",
      "Area under curve: 0.9926975699115551\n",
      "Final Confusion Matrix\n",
      "[[2.8496e+03 2.6000e+00]\n",
      " [1.7600e+01 8.0800e+01]]\n",
      "F1 score: 0.888888888888889\n",
      "Recall: 0.8211382113821137\n",
      "Precision: 0.9688249400479617\n",
      "AUC: 0.9802539717306118\n",
      "Checking class weight None and coefficient 0.027825594022071243\n",
      "Fold 0\n",
      "[[2852    1]\n",
      " [  19   80]]\n",
      "Area under curve: 0.976735458333776\n",
      "Fold 1\n",
      "[[2848    4]\n",
      " [  19   80]]\n",
      "Area under curve: 0.964936886395512\n",
      "Fold 2\n",
      "[[2852    0]\n",
      " [  16   82]]\n",
      "Area under curve: 0.9833521767753385\n",
      "Fold 3\n",
      "[[2849    3]\n",
      " [  15   83]]\n",
      "Area under curve: 0.9828763202335634\n",
      "Fold 4\n",
      "[[2847    5]\n",
      " [  19   79]]\n",
      "Area under curve: 0.9928049059736097\n",
      "Final Confusion Matrix\n",
      "[[2.8496e+03 2.6000e+00]\n",
      " [1.7600e+01 8.0800e+01]]\n",
      "F1 score: 0.888888888888889\n",
      "Recall: 0.8211382113821137\n",
      "Precision: 0.9688249400479617\n",
      "AUC: 0.9801411495423599\n",
      "Checking class weight None and coefficient 0.046415888336127774\n",
      "Fold 0\n",
      "[[2852    1]\n",
      " [  19   80]]\n",
      "Area under curve: 0.9747492449910957\n",
      "Fold 1\n",
      "[[2848    4]\n",
      " [  19   80]]\n",
      "Area under curve: 0.9655708558233103\n",
      "Fold 2\n",
      "[[2851    1]\n",
      " [  15   83]]\n",
      "Area under curve: 0.98279760712139\n",
      "Fold 3\n",
      "[[2849    3]\n",
      " [  15   83]]\n",
      "Area under curve: 0.9827725620402439\n",
      "Fold 4\n",
      "[[2848    4]\n",
      " [  19   79]]\n",
      "Area under curve: 0.992507942868592\n",
      "Final Confusion Matrix\n",
      "[[2.8496e+03 2.6000e+00]\n",
      " [1.7400e+01 8.1000e+01]]\n",
      "F1 score: 0.8901098901098902\n",
      "Recall: 0.823170731707317\n",
      "Precision: 0.9688995215311006\n",
      "AUC: 0.9796796425689264\n",
      "Checking class weight None and coefficient 0.0774263682681127\n",
      "Fold 0\n",
      "[[2852    1]\n",
      " [  19   80]]\n",
      "Area under curve: 0.9732197545026147\n",
      "Fold 1\n",
      "[[2848    4]\n",
      " [  19   80]]\n",
      "Area under curve: 0.9660808647484664\n",
      "Fold 2\n",
      "[[2851    1]\n",
      " [  15   83]]\n",
      "Area under curve: 0.9823145948421443\n",
      "Fold 3\n",
      "[[2850    2]\n",
      " [  15   83]]\n",
      "Area under curve: 0.9824469759853451\n",
      "Fold 4\n",
      "[[2848    4]\n",
      " [  19   79]]\n",
      "Area under curve: 0.9921465781263418\n",
      "Final Confusion Matrix\n",
      "[[2.8498e+03 2.4000e+00]\n",
      " [1.7400e+01 8.1000e+01]]\n",
      "F1 score: 0.8910891089108911\n",
      "Recall: 0.823170731707317\n",
      "Precision: 0.9712230215827338\n",
      "AUC: 0.9792417536409823\n",
      "Checking class weight None and coefficient 0.1291549665014884\n",
      "Fold 0\n",
      "[[2852    1]\n",
      " [  19   80]]\n",
      "Area under curve: 0.9719487195827891\n",
      "Fold 1\n",
      "[[2848    4]\n",
      " [  19   80]]\n",
      "Area under curve: 0.966665249975208\n",
      "Fold 2\n",
      "[[2850    2]\n",
      " [  15   83]]\n",
      "Area under curve: 0.9815632424077625\n",
      "Fold 3\n",
      "[[2850    2]\n",
      " [  16   82]]\n",
      "Area under curve: 0.9819997423934511\n",
      "Fold 4\n",
      "[[2848    4]\n",
      " [  19   79]]\n",
      "Area under curve: 0.9917422789592695\n",
      "Final Confusion Matrix\n",
      "[[2.8496e+03 2.6000e+00]\n",
      " [1.7600e+01 8.0800e+01]]\n",
      "F1 score: 0.888888888888889\n",
      "Recall: 0.8211382113821137\n",
      "Precision: 0.9688249400479617\n",
      "AUC: 0.9787838466636961\n",
      "Checking class weight None and coefficient 0.21544346900318834\n",
      "Fold 0\n",
      "[[2852    1]\n",
      " [  19   80]]\n",
      "Area under curve: 0.9708051422036699\n",
      "Fold 1\n",
      "[[2848    4]\n",
      " [  19   80]]\n",
      "Area under curve: 0.9671823423576579\n",
      "Fold 2\n",
      "[[2849    3]\n",
      " [  15   83]]\n",
      "Area under curve: 0.9808190457108509\n",
      "Fold 3\n",
      "[[2850    2]\n",
      " [  17   81]]\n",
      "Area under curve: 0.981434439133297\n",
      "Fold 4\n",
      "[[2848    4]\n",
      " [  19   79]]\n",
      "Area under curve: 0.9911447748804992\n",
      "Final Confusion Matrix\n",
      "[[2.8494e+03 2.8000e+00]\n",
      " [1.7800e+01 8.0600e+01]]\n",
      "F1 score: 0.8866886688668867\n",
      "Recall: 0.8191056910569106\n",
      "Precision: 0.9664268585131894\n",
      "AUC: 0.978277148857195\n",
      "Checking class weight None and coefficient 0.3593813663804626\n",
      "Fold 0\n",
      "[[2852    1]\n",
      " [  19   80]]\n",
      "Area under curve: 0.9701466115766852\n",
      "Fold 1\n",
      "[[2848    4]\n",
      " [  19   80]]\n",
      "Area under curve: 0.967741935483871\n",
      "Fold 2\n",
      "[[2849    3]\n",
      " [  15   83]]\n",
      "Area under curve: 0.9801714514697885\n",
      "Fold 3\n",
      "[[2850    2]\n",
      " [  16   82]]\n",
      "Area under curve: 0.9809836276726679\n",
      "Fold 4\n",
      "[[2848    4]\n",
      " [  19   79]]\n",
      "Area under curve: 0.9906295617826374\n",
      "Final Confusion Matrix\n",
      "[[2.8494e+03 2.8000e+00]\n",
      " [1.7600e+01 8.0800e+01]]\n",
      "F1 score: 0.8879120879120879\n",
      "Recall: 0.8211382113821137\n",
      "Precision: 0.9665071770334929\n",
      "AUC: 0.9779346375971298\n",
      "Checking class weight None and coefficient 0.5994842503189409\n",
      "Fold 0\n",
      "[[2852    1]\n",
      " [  19   80]]\n",
      "Area under curve: 0.9694172712048632\n",
      "Fold 1\n",
      "[[2848    4]\n",
      " [  20   79]]\n",
      "Area under curve: 0.9681704846501481\n",
      "Fold 2\n",
      "[[2849    3]\n",
      " [  15   83]]\n",
      "Area under curve: 0.979738529352835\n",
      "Fold 3\n",
      "[[2851    1]\n",
      " [  16   82]]\n",
      "Area under curve: 0.9805650170306552\n",
      "Fold 4\n",
      "[[2848    4]\n",
      " [  19   79]]\n",
      "Area under curve: 0.9901572831095973\n",
      "Final Confusion Matrix\n",
      "[[2.8496e+03 2.6000e+00]\n",
      " [1.7800e+01 8.0600e+01]]\n",
      "F1 score: 0.8876651982378855\n",
      "Recall: 0.8191056910569106\n",
      "Precision: 0.9687500000000001\n",
      "AUC: 0.9776097170696196\n",
      "Checking class weight None and coefficient 1.0\n",
      "Fold 0\n",
      "[[2852    1]\n",
      " [  18   81]]\n",
      "Area under curve: 0.9689180625037618\n",
      "Fold 1\n",
      "[[2848    4]\n",
      " [  20   79]]\n",
      "Area under curve: 0.9684609063991954\n",
      "Fold 2\n",
      "[[2849    3]\n",
      " [  15   83]]\n",
      "Area under curve: 0.9792125826487678\n",
      "Fold 3\n",
      "[[2851    1]\n",
      " [  16   82]]\n",
      "Area under curve: 0.9802000744196697\n",
      "Fold 4\n",
      "[[2848    4]\n",
      " [  19   79]]\n",
      "Area under curve: 0.9898066519735523\n",
      "Final Confusion Matrix\n",
      "[[2.8496e+03 2.6000e+00]\n",
      " [1.7600e+01 8.0800e+01]]\n",
      "F1 score: 0.888888888888889\n",
      "Recall: 0.8211382113821137\n",
      "Precision: 0.9688249400479617\n",
      "AUC: 0.9773196555889895\n",
      "Checking class weight balanced and coefficient 0.01\n",
      "Fold 0\n",
      "[[2805   48]\n",
      " [  11   88]]\n",
      "Area under curve: 0.9727382482377226\n",
      "Fold 1\n",
      "[[2792   60]\n",
      " [  14   85]]\n",
      "Area under curve: 0.9662508677235185\n",
      "Fold 2\n",
      "[[2797   55]\n",
      " [  11   87]]\n",
      "Area under curve: 0.9813235252025073\n",
      "Fold 3\n",
      "[[2795   57]\n",
      " [   7   91]]\n",
      "Area under curve: 0.9812126112717178\n",
      "Fold 4\n",
      "[[2782   70]\n",
      " [   7   91]]\n",
      "Area under curve: 0.9916921887969774\n",
      "Final Confusion Matrix\n",
      "[[2794.2   58. ]\n",
      " [  10.    88.4]]\n",
      "F1 score: 0.7222222222222223\n",
      "Recall: 0.8983739837398375\n",
      "Precision: 0.6038251366120219\n",
      "AUC: 0.9786434882464887\n",
      "Checking class weight balanced and coefficient 0.016681005372000592\n",
      "Fold 0\n",
      "[[2804   49]\n",
      " [  10   89]]\n",
      "Area under curve: 0.9718814503251937\n",
      "Fold 1\n",
      "[[2789   63]\n",
      " [  14   85]]\n",
      "Area under curve: 0.9667077507189709\n",
      "Fold 2\n",
      "[[2794   58]\n",
      " [  10   88]]\n",
      "Area under curve: 0.9812233448779231\n",
      "Fold 3\n",
      "[[2794   58]\n",
      " [   7   91]]\n",
      "Area under curve: 0.9810659186535764\n",
      "Fold 4\n",
      "[[2783   69]\n",
      " [   6   92]]\n",
      "Area under curve: 0.9914131150356356\n",
      "Final Confusion Matrix\n",
      "[[2792.8   59.4]\n",
      " [   9.4   89. ]]\n",
      "F1 score: 0.7212317666126418\n",
      "Recall: 0.9044715447154471\n",
      "Precision: 0.5997304582210242\n",
      "AUC: 0.97845831592226\n",
      "Checking class weight balanced and coefficient 0.027825594022071243\n",
      "Fold 0\n",
      "[[2803   50]\n",
      " [  10   89]]\n",
      "Area under curve: 0.9709078163336838\n",
      "Fold 1\n",
      "[[2785   67]\n",
      " [  14   85]]\n",
      "Area under curve: 0.9669415048096676\n",
      "Fold 2\n",
      "[[2794   58]\n",
      " [  10   88]]\n",
      "Area under curve: 0.9809764719351977\n",
      "Fold 3\n",
      "[[2793   59]\n",
      " [   7   91]]\n",
      "Area under curve: 0.9809585825915219\n",
      "Fold 4\n",
      "[[2781   71]\n",
      " [   6   92]]\n",
      "Area under curve: 0.991116151930618\n",
      "Final Confusion Matrix\n",
      "[[2791.2   61. ]\n",
      " [   9.4   89. ]]\n",
      "F1 score: 0.71658615136876\n",
      "Recall: 0.9044715447154471\n",
      "Precision: 0.5933333333333334\n",
      "AUC: 0.9781801055201378\n",
      "Checking class weight balanced and coefficient 0.046415888336127774\n",
      "Fold 0\n",
      "[[2802   51]\n",
      " [  10   89]]\n",
      "Area under curve: 0.9700899637808156\n",
      "Fold 1\n",
      "[[2784   68]\n",
      " [  14   85]]\n",
      "Area under curve: 0.967001714196665\n",
      "Fold 2\n",
      "[[2792   60]\n",
      " [  10   88]]\n",
      "Area under curve: 0.9806973981738558\n",
      "Fold 3\n",
      "[[2793   59]\n",
      " [   7   91]]\n",
      "Area under curve: 0.9808834473480836\n",
      "Fold 4\n",
      "[[2781   71]\n",
      " [   6   92]]\n",
      "Area under curve: 0.9907082748948106\n",
      "Final Confusion Matrix\n",
      "[[2790.4   61.8]\n",
      " [   9.4   89. ]]\n",
      "F1 score: 0.7142857142857143\n",
      "Recall: 0.9044715447154471\n",
      "Precision: 0.5901856763925729\n",
      "AUC: 0.9778761596788461\n",
      "Checking class weight balanced and coefficient 0.0774263682681127\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0\n",
      "[[2800   53]\n",
      " [  10   89]]\n",
      "Area under curve: 0.9693110565876076\n",
      "Fold 1\n",
      "[[2782   70]\n",
      " [  14   85]]\n",
      "Area under curve: 0.967090257412838\n",
      "Fold 2\n",
      "[[2788   64]\n",
      " [  10   88]]\n",
      "Area under curve: 0.9805256604745686\n",
      "Fold 3\n",
      "[[2792   60]\n",
      " [   6   92]]\n",
      "Area under curve: 0.9808154678421157\n",
      "Fold 4\n",
      "[[2780   72]\n",
      " [   6   92]]\n",
      "Area under curve: 0.9904900249019664\n",
      "Final Confusion Matrix\n",
      "[[2788.4   63.8]\n",
      " [   9.2   89.2]]\n",
      "F1 score: 0.709626093874304\n",
      "Recall: 0.9065040650406504\n",
      "Precision: 0.5830065359477125\n",
      "AUC: 0.9776464934438192\n",
      "Checking class weight balanced and coefficient 0.1291549665014884\n",
      "Fold 0\n",
      "[[2800   53]\n",
      " [  10   89]]\n",
      "Area under curve: 0.968695011807525\n",
      "Fold 1\n",
      "[[2779   73]\n",
      " [  14   85]]\n",
      "Area under curve: 0.9672177596441272\n",
      "Fold 2\n",
      "[[2787   65]\n",
      " [  10   88]]\n",
      "Area under curve: 0.9803575006440164\n",
      "Fold 3\n",
      "[[2792   60]\n",
      " [   6   92]]\n",
      "Area under curve: 0.9808691358731431\n",
      "Fold 4\n",
      "[[2780   72]\n",
      " [   6   92]]\n",
      "Area under curve: 0.9902467298279761\n",
      "Final Confusion Matrix\n",
      "[[2787.6   64.6]\n",
      " [   9.2   89.2]]\n",
      "F1 score: 0.7073750991276766\n",
      "Recall: 0.9065040650406504\n",
      "Precision: 0.5799739921976593\n",
      "AUC: 0.9774772275593575\n",
      "Checking class weight balanced and coefficient 0.21544346900318834\n",
      "Fold 0\n",
      "[[2799   54]\n",
      " [  10   89]]\n",
      "Area under curve: 0.9682524509022932\n",
      "Fold 1\n",
      "[[2779   73]\n",
      " [  14   85]]\n",
      "Area under curve: 0.967309844588947\n",
      "Fold 2\n",
      "[[2787   65]\n",
      " [  10   88]]\n",
      "Area under curve: 0.9803682342502219\n",
      "Fold 3\n",
      "[[2793   59]\n",
      " [   6   92]]\n",
      "Area under curve: 0.980940693247846\n",
      "Fold 4\n",
      "[[2780   72]\n",
      " [   6   92]]\n",
      "Area under curve: 0.9901322380284512\n",
      "Final Confusion Matrix\n",
      "[[2787.6   64.6]\n",
      " [   9.2   89.2]]\n",
      "F1 score: 0.7073750991276766\n",
      "Recall: 0.9065040650406504\n",
      "Precision: 0.5799739921976593\n",
      "AUC: 0.9774006922035519\n",
      "Checking class weight balanced and coefficient 0.3593813663804626\n",
      "Fold 0\n",
      "[[2801   52]\n",
      " [  10   89]]\n",
      "Area under curve: 0.9679550499739774\n",
      "Fold 1\n",
      "[[2776   76]\n",
      " [  14   85]]\n",
      "Area under curve: 0.9674568263277941\n",
      "Fold 2\n",
      "[[2785   67]\n",
      " [  10   88]]\n",
      "Area under curve: 0.9803181440879297\n",
      "Fold 3\n",
      "[[2791   61]\n",
      " [   6   92]]\n",
      "Area under curve: 0.9809979391476086\n",
      "Fold 4\n",
      "[[2781   71]\n",
      " [   6   92]]\n",
      "Area under curve: 0.9900284798351319\n",
      "Final Confusion Matrix\n",
      "[[2786.8   65.4]\n",
      " [   9.2   89.2]]\n",
      "F1 score: 0.7051383399209485\n",
      "Recall: 0.9065040650406504\n",
      "Precision: 0.5769728331177231\n",
      "AUC: 0.9773512878744883\n",
      "Checking class weight balanced and coefficient 0.5994842503189409\n",
      "Fold 0\n",
      "[[2800   53]\n",
      " [   9   90]]\n",
      "Area under curve: 0.9676346358785897\n",
      "Fold 1\n",
      "[[2776   76]\n",
      " [  14   85]]\n",
      "Area under curve: 0.9676587048606685\n",
      "Fold 2\n",
      "[[2785   67]\n",
      " [  10   88]]\n",
      "Area under curve: 0.9803324555628703\n",
      "Fold 3\n",
      "[[2789   63]\n",
      " [   6   92]]\n",
      "Area under curve: 0.9810945416034577\n",
      "Fold 4\n",
      "[[2781   71]\n",
      " [   6   92]]\n",
      "Area under curve: 0.9900392134413374\n",
      "Final Confusion Matrix\n",
      "[[2786.2   66. ]\n",
      " [   9.    89.4]]\n",
      "F1 score: 0.7044917257683214\n",
      "Recall: 0.9085365853658537\n",
      "Precision: 0.5752895752895753\n",
      "AUC: 0.9773519102693846\n",
      "Checking class weight balanced and coefficient 1.0\n",
      "Fold 0\n",
      "[[2799   54]\n",
      " [   9   90]]\n",
      "Area under curve: 0.9674239768876992\n",
      "Fold 1\n",
      "[[2776   76]\n",
      " [  14   85]]\n",
      "Area under curve: 0.9677490189411647\n",
      "Fold 2\n",
      "[[2785   67]\n",
      " [  10   88]]\n",
      "Area under curve: 0.9803288776941351\n",
      "Fold 3\n",
      "[[2791   61]\n",
      " [   6   92]]\n",
      "Area under curve: 0.9811589432406903\n",
      "Fold 4\n",
      "[[2779   73]\n",
      " [   6   92]]\n",
      "Area under curve: 0.9900427913100723\n",
      "Final Confusion Matrix\n",
      "[[2786.    66.2]\n",
      " [   9.    89.4]]\n",
      "F1 score: 0.7039370078740158\n",
      "Recall: 0.9085365853658537\n",
      "Precision: 0.5745501285347043\n",
      "AUC: 0.9773407216147524\n",
      "Best parameters found for Logistic Regression under AUC metric is None class weights and 0.016681005372000592 coefficient\n",
      "Best parameters found for Logistic Regression under F1 metric is None class weights and 0.01 coefficient\n",
      "Best parameters found for Logistic Regression under precision metric is None class weights and 0.0774263682681127 coefficient\n",
      "Best parameters found for Logistic Regression under recall metric is balanced class weights and 0.5994842503189409 coefficient\n"
     ]
    }
   ],
   "source": [
    "weights = [None,'balanced']\n",
    "coefficients = np.logspace(-2,0,10)\n",
    "fscore = []\n",
    "recall = []\n",
    "precision = []\n",
    "AU = []\n",
    "param_permuations = list(itertools.product(weights, coefficients))\n",
    "for cw,C in param_permuations:\n",
    "    print('Checking class weight {} and coefficient {}'.format(cw, C))\n",
    "    cf,au = train_logistic_regression(data_sc, cw, C)\n",
    "    TP = cf[1][1]\n",
    "    FP = cf[0][1]\n",
    "    FN = cf[1][0]\n",
    "    prec = TP/(TP+FP)\n",
    "    rec = TP/(TP+FN)\n",
    "    f1 = prec*rec*2/(prec+rec)\n",
    "    print('F1 score:', f1)\n",
    "    print('Recall:', rec)\n",
    "    print('Precision:', prec)\n",
    "    print('AUC:', au)\n",
    "    fscore.append(f1)\n",
    "    recall.append(rec)\n",
    "    precision.append(prec)\n",
    "    AU.append(au)\n",
    "\n",
    "idx = np.argmax(AU)\n",
    "best_params = param_permuations[idx]\n",
    "print('Best parameters found for Logistic Regression under AUC metric is {} class weights and {} coefficient'.format(best_params[0], best_params[1]))\n",
    "\n",
    "idx = np.argmax(f1)\n",
    "best_params = param_permuations[idx]\n",
    "print('Best parameters found for Logistic Regression under F1 metric is {} class weights and {} coefficient'.format(best_params[0], best_params[1]))\n",
    "\n",
    "idx = np.argmax(precision)\n",
    "best_params = param_permuations[idx]\n",
    "print('Best parameters found for Logistic Regression under precision metric is {} class weights and {} coefficient'.format(best_params[0], best_params[1]))\n",
    "\n",
    "idx = np.argmax(recall)\n",
    "best_params = param_permuations[idx]\n",
    "print('Best parameters found for Logistic Regression under recall metric is {} class weights and {} coefficient'.format(best_params[0], best_params[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_KNN(data, k, scale=False):\n",
    "    confusion_mat = np.zeros((2, 2))\n",
    "    for i in range(5):\n",
    "        knn = KNeighborsClassifier(n_neighbors=k)\n",
    "        \n",
    "        train_data = np.delete(data, folds[i], axis=0)\n",
    "        test_data = data[folds[i]]\n",
    "        if scale:\n",
    "            scaler = StandardScaler()\n",
    "            train_data = scaler.fit_transform(train_data)\n",
    "            test_data = scaler.transform(test_data)\n",
    "\n",
    "        knn.fit(train_data, np.delete(labels, folds[i]))\n",
    "        pred = knn.predict(test_data)\n",
    "\n",
    "        conf_mat = confusion_matrix(labels[folds[i]], pred)\n",
    "        print('Fold', i)\n",
    "        print(conf_mat)\n",
    "\n",
    "        confusion_mat += conf_mat\n",
    "\n",
    "    confusion_mat /= 5\n",
    "    print('Final Confusion Matrix')\n",
    "    print(confusion_mat)\n",
    "    print('False negatives (valid):', confusion_mat[0, 1] / sum(confusion_mat[0, :]))\n",
    "    print('False positives (fraud):', confusion_mat[1, 0] / sum(confusion_mat[1,:]))\n",
    "    return confusion_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0\n",
      "[[2852    1]\n",
      " [  28   71]]\n",
      "Fold 1\n",
      "[[2847    5]\n",
      " [  24   75]]\n",
      "Fold 2\n",
      "[[2852    0]\n",
      " [  31   67]]\n",
      "Fold 3\n",
      "[[2848    4]\n",
      " [  29   69]]\n",
      "Fold 4\n",
      "[[2848    4]\n",
      " [  29   69]]\n",
      "Final Confusion Matrix\n",
      "[[2.8494e+03 2.8000e+00]\n",
      " [2.8200e+01 7.0200e+01]]\n",
      "False negatives (valid): 0.000981698338124956\n",
      "False positives (fraud): 0.2865853658536585\n",
      "Confusion Matrix:\n",
      "[[2.8494e+03 2.8000e+00]\n",
      " [2.8200e+01 7.0200e+01]]\n",
      "\n",
      "Fold 0\n",
      "[[2852    1]\n",
      " [  33   66]]\n",
      "Fold 1\n",
      "[[2846    6]\n",
      " [  26   73]]\n",
      "Fold 2\n",
      "[[2852    0]\n",
      " [  31   67]]\n",
      "Fold 3\n",
      "[[2850    2]\n",
      " [  32   66]]\n",
      "Fold 4\n",
      "[[2848    4]\n",
      " [  31   67]]\n",
      "Final Confusion Matrix\n",
      "[[2.8496e+03 2.6000e+00]\n",
      " [3.0600e+01 6.7800e+01]]\n",
      "False negatives (valid): 0.000911577028258888\n",
      "False positives (fraud): 0.31097560975609756\n",
      "Confusion Matrix:\n",
      "[[2.8496e+03 2.6000e+00]\n",
      " [3.0600e+01 6.7800e+01]]\n",
      "\n",
      "Fold 0\n",
      "[[2852    1]\n",
      " [  35   64]]\n",
      "Fold 1\n",
      "[[2847    5]\n",
      " [  27   72]]\n",
      "Fold 2\n",
      "[[2851    1]\n",
      " [  36   62]]\n",
      "Fold 3\n",
      "[[2850    2]\n",
      " [  33   65]]\n",
      "Fold 4\n",
      "[[2848    4]\n",
      " [  37   61]]\n",
      "Final Confusion Matrix\n",
      "[[2.8496e+03 2.6000e+00]\n",
      " [3.3600e+01 6.4800e+01]]\n",
      "False negatives (valid): 0.000911577028258888\n",
      "False positives (fraud): 0.3414634146341463\n",
      "Confusion Matrix:\n",
      "[[2.8496e+03 2.6000e+00]\n",
      " [3.3600e+01 6.4800e+01]]\n",
      "\n",
      "Fold 0\n",
      "[[2852    1]\n",
      " [  35   64]]\n",
      "Fold 1\n",
      "[[2846    6]\n",
      " [  28   71]]\n",
      "Fold 2\n",
      "[[2852    0]\n",
      " [  36   62]]\n",
      "Fold 3\n",
      "[[2850    2]\n",
      " [  33   65]]\n",
      "Fold 4\n",
      "[[2848    4]\n",
      " [  41   57]]\n",
      "Final Confusion Matrix\n",
      "[[2.8496e+03 2.6000e+00]\n",
      " [3.4600e+01 6.3800e+01]]\n",
      "False negatives (valid): 0.000911577028258888\n",
      "False positives (fraud): 0.3516260162601626\n",
      "Confusion Matrix:\n",
      "[[2.8496e+03 2.6000e+00]\n",
      " [3.4600e+01 6.3800e+01]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for k in [5, 7, 9, 11]:\n",
    "    conf = train_KNN(data, k)\n",
    "    print('Confusion Matrix:')\n",
    "    print(conf)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
