{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import itertools\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# import warnings\n",
    "# warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data is imbalanced, with 284807 samples in total but only 492 cases of fraud\n"
     ]
    }
   ],
   "source": [
    "with open('creditcard.csv', newline='') as f:\n",
    "    reader = csv.reader(f, delimiter=',')\n",
    "    csv_data = list(reader)[1:]\n",
    "\n",
    "# Format: Time, V1, ..., V28, Amount, Class\n",
    "data = np.array([[float(x) for x in row[1:-1]] for row in csv_data])\n",
    "times = np.array([float(row[0]) for row in csv_data])\n",
    "labels = np.array([int(row[-1]) for row in csv_data])\n",
    "print('The data is imbalanced, with {} samples in total but only {} cases of fraud'.format(len(labels), sum(labels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  3.91864870e-15   5.68268579e-16  -8.76173610e-15   2.81111774e-15\n",
      "  -1.55210305e-15   2.04012968e-15  -1.69895265e-15  -1.95815061e-16\n",
      "  -3.14764036e-15   1.77292451e-15   9.28952385e-16  -1.80326603e-15\n",
      "   1.67488824e-15   1.47562122e-15   3.50109813e-15   1.39243845e-15\n",
      "  -7.46653801e-16   4.25873794e-16   9.02016885e-16   5.12684532e-16\n",
      "   1.47198194e-16   8.04210901e-16   5.28245009e-16   4.45826738e-15\n",
      "   1.42689564e-15   1.70163965e-15  -3.67160561e-16  -1.21815215e-16\n",
      "   8.83496193e+01]\n",
      "[  3.83647578e+00   2.72681045e+00   2.29902117e+00   2.00467678e+00\n",
      "   1.90507436e+00   1.77494002e+00   1.53039520e+00   1.42647385e+00\n",
      "   1.20698823e+00   1.18558965e+00   1.04185143e+00   9.98399911e-01\n",
      "   9.90567315e-01   9.18902320e-01   8.37800459e-01   7.67816427e-01\n",
      "   7.21370915e-01   7.02536891e-01   6.62659610e-01   5.94323307e-01\n",
      "   5.39523633e-01   5.26640906e-01   3.89949292e-01   3.66807083e-01\n",
      "   2.71729873e-01   2.32542076e-01   1.62918619e-01   1.08954579e-01\n",
      "   6.25598494e+04]\n",
      "The PCA features have mean 0 but different variances\n",
      "The transaction amount is not scaled. We should scale it so it does not affect the SVM too much\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(data, axis=0))\n",
    "print(np.var(data, axis=0))\n",
    "print('The PCA features have mean 0 but different variances')\n",
    "print('The transaction amount is not scaled. We should scale it so it does not affect the SVM too much')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preliminary plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.19185711 -1.35835406 -0.96627171 -1.15823309 -0.42596588  1.22965763\n",
      " -0.64426944 -0.89428608 -0.33826175]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb670329d68>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the first two principal components\n",
    "data_fraud = data[np.where(labels == 1)]\n",
    "data_valid = data[np.where(labels == 0)]\n",
    "plt.scatter(data_valid[:, 0], data_valid[:, -1], c='b')\n",
    "plt.scatter(data_fraud[:, 0], data_fraud[:, -1], c='r')\n",
    "print(data_valid[1:10, 0])\n",
    "plt.ylim((0, 10000))\n",
    "plt.legend(['valid', 'fraud'])\n",
    "plt.xlabel('First PCA feature')\n",
    "plt.ylabel('Transaction amount')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraud_indices = np.where(labels == 1)[0]\n",
    "np.random.shuffle(fraud_indices)\n",
    "fraud_splits = np.array_split(fraud_indices, 5)\n",
    "\n",
    "valid_indices = np.where(labels == 0)[0]\n",
    "np.random.shuffle(valid_indices)\n",
    "valid_splits = np.array_split(valid_indices, 5)\n",
    "\n",
    "folds = [np.concatenate((fraud_sp, valid_sp)) for fraud_sp, valid_sp in zip(fraud_splits, valid_splits)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_binary_SVM(data, scale=False, kernel=None, class_weight=None):\n",
    "    confusion_mat = np.zeros((2, 2))\n",
    "    for i in range(5):\n",
    "        if kernel is None:\n",
    "            if class_weight is None:\n",
    "                svm = LinearSVC(fit_intercept=False, dual=False)\n",
    "            else:\n",
    "                svm = LinearSVC(fit_intercept=False, dual=False, class_weight=class_weight)\n",
    "        else:\n",
    "            if class_weight is None:\n",
    "                svm = SVC(kernel=kernel, gamma='auto')\n",
    "            else:\n",
    "                svm = SVC(kernel=kernel, gamma='auto', class_weight=class_weight)\n",
    "        \n",
    "        train_data = np.delete(data, folds[i], axis=0)\n",
    "        test_data = data[folds[i]]\n",
    "        if scale:\n",
    "            scaler = StandardScaler()\n",
    "            train_data = scaler.fit_transform(train_data)\n",
    "            test_data = scaler.transform(test_data)\n",
    "\n",
    "        svm.fit(train_data, np.delete(labels, folds[i]))\n",
    "        pred = svm.predict(test_data)\n",
    "\n",
    "        conf_mat = confusion_matrix(labels[folds[i]], pred)\n",
    "        print('Fold', i)\n",
    "        print(conf_mat)\n",
    "\n",
    "        confusion_mat += conf_mat\n",
    "\n",
    "    confusion_mat /= 5\n",
    "    print('Final Confusion Matrix')\n",
    "    print(confusion_mat)\n",
    "    print('False negatives (valid):', confusion_mat[0, 1] / sum(confusion_mat[0, :]))\n",
    "    print('False positives (fraud):', confusion_mat[1, 0] / sum(confusion_mat[1,:]))\n",
    "    return confusion_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear SVM -- Without scaling or class weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0\n",
      "[[56826    37]\n",
      " [   43    56]]\n",
      "Fold 1\n",
      "[[56828    35]\n",
      " [   34    65]]\n",
      "Fold 2\n",
      "[[56833    30]\n",
      " [   34    64]]\n",
      "Fold 3\n",
      "[[56808    55]\n",
      " [   36    62]]\n",
      "Fold 4\n",
      "[[56824    39]\n",
      " [   31    67]]\n",
      "Final Confusion Matrix\n",
      "[[  5.68238000e+04   3.92000000e+01]\n",
      " [  3.56000000e+01   6.28000000e+01]]\n",
      "False negatives (valid): 0.000689376220038\n",
      "False positives (fraud): 0.361788617886\n"
     ]
    }
   ],
   "source": [
    "train_binary_SVM(data);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear SVM with Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0\n",
      "[[49053  7810]\n",
      " [    4    95]]\n",
      "Fold 1\n",
      "[[48482  8381]\n",
      " [    3    96]]\n",
      "Fold 2\n",
      "[[49870  6993]\n",
      " [    4    94]]\n",
      "Fold 3\n",
      "[[50381  6482]\n",
      " [    6    92]]\n",
      "Fold 4\n",
      "[[48856  8007]\n",
      " [    3    95]]\n",
      "Final Confusion Matrix\n",
      "[[  4.93284000e+04   7.53460000e+03]\n",
      " [  4.00000000e+00   9.44000000e+01]]\n",
      "False negatives (valid): 0.132504440497\n",
      "False positives (fraud): 0.0406504065041\n"
     ]
    }
   ],
   "source": [
    "train_binary_SVM(data, scale=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear SVM with Scaling and Class Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0\n",
      "[[33547 23316]\n",
      " [    1    98]]\n",
      "Fold 1\n",
      "[[34436 22427]\n",
      " [    0    99]]\n",
      "Fold 2\n",
      "[[34014 22849]\n",
      " [    0    98]]\n",
      "Fold 3\n",
      "[[34283 22580]\n",
      " [    1    97]]\n",
      "Fold 4\n",
      "[[33524 23339]\n",
      " [    2    96]]\n",
      "Final Confusion Matrix\n",
      "[[  3.39608000e+04   2.29022000e+04]\n",
      " [  8.00000000e-01   9.76000000e+01]]\n",
      "False negatives (valid): 0.402761022106\n",
      "False positives (fraud): 0.00813008130081\n"
     ]
    }
   ],
   "source": [
    "train_binary_SVM(data, scale=True, class_weight='balanced');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kernel SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RBF Kernel with Scaling and Class Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_binary_SVM(data, scale=True, kernel='rbf');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_binary_SVM(data, kernel='rbf', class_weight='balanced');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Polynomial Kernel with Scaling and Class Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_binary_SVM(data, scale=True, kernel='poly');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_binary_SVM(data, scale=True, kernel='poly', class_weight='balanced');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_logistic_regression(data, class_weight = None, C=1.0):\n",
    "    err = 0\n",
    "    err_valid = 0\n",
    "    err_fraud = 0\n",
    "    confusion_mat = np.zeros((2, 2))\n",
    "    for i in range(5):\n",
    "        model = LogisticRegression(class_weight=class_weight, C=C)\n",
    "        \n",
    "        model.fit(np.delete(data, folds[i], axis=0), np.delete(labels, folds[i]))\n",
    "        pred = model.predict(data[folds[i]])\n",
    "        err_fold = np.sum((pred - labels[folds[i]])**2) / len(folds[i])\n",
    "        pred_valid = model.predict(data[valid_splits[i]])\n",
    "        err_valid_fold = np.sum((pred_valid - labels[valid_splits[i]])**2) / len(valid_splits[i])\n",
    "        pred_fraud = model.predict(data[fraud_splits[i]])\n",
    "        err_fraud_fold = np.sum((pred_fraud - labels[fraud_splits[i]])**2) / len(fraud_splits[i])\n",
    "        #print('Fold', i, 'Error:', err_fold, 'Valid Error:', err_valid_fold, 'Fraud Error', err_fraud_fold)\n",
    "        err += err_fold\n",
    "        err_valid += err_valid_fold\n",
    "        err_fraud += err_fraud_fold\n",
    "        conf_mat = confusion_matrix(labels[folds[i]], pred)\n",
    "        print('Fold', i)\n",
    "        print(conf_mat)\n",
    "\n",
    "        confusion_mat += conf_mat\n",
    "    confusion_mat /= 5\n",
    "    print('Final Confusion Matrix')\n",
    "    print(confusion_mat)\n",
    "    return confusion_mat\n",
    "    #err /= 5\n",
    "    #err_valid /= 5\n",
    "    #err_fraud /= 5\n",
    "    #print('FINAL Error:', err, 'Valid Error:', err_valid, 'Fraud Error', err_fraud)\n",
    "    #return err, err_valid, err_fraud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression with Scaling, Class Weights, and Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking class weight None and coefficient 0.01\n",
      "Fold 0\n",
      "[[56850    13]\n",
      " [   45    54]]\n",
      "Fold 1\n",
      "[[56860     3]\n",
      " [   42    57]]\n",
      "Fold 2\n",
      "[[56858     5]\n",
      " [   35    63]]\n",
      "Fold 3\n",
      "[[56856     7]\n",
      " [   39    59]]\n",
      "Fold 4\n",
      "[[56852    11]\n",
      " [   42    56]]\n",
      "Final Confusion Matrix\n",
      "[[5.68552e+04 7.80000e+00]\n",
      " [4.06000e+01 5.78000e+01]]\n",
      "F1 score: 0.7048780487804878\n",
      "Recall: 0.5873983739837397\n",
      "Precision: 0.8810975609756098\n",
      "Checking class weight None and coefficient 0.016681005372000592\n",
      "Fold 0\n",
      "[[56850    13]\n",
      " [   46    53]]\n",
      "Fold 1\n",
      "[[56860     3]\n",
      " [   41    58]]\n",
      "Fold 2\n",
      "[[56858     5]\n",
      " [   35    63]]\n",
      "Fold 3\n",
      "[[56856     7]\n",
      " [   38    60]]\n",
      "Fold 4\n",
      "[[56852    11]\n",
      " [   42    56]]\n",
      "Final Confusion Matrix\n",
      "[[5.68552e+04 7.80000e+00]\n",
      " [4.04000e+01 5.80000e+01]]\n",
      "F1 score: 0.7064555420219245\n",
      "Recall: 0.589430894308943\n",
      "Precision: 0.8814589665653496\n",
      "Checking class weight None and coefficient 0.027825594022071243\n",
      "Fold 0\n",
      "[[56850    13]\n",
      " [   46    53]]\n",
      "Fold 1\n",
      "[[56860     3]\n",
      " [   41    58]]\n",
      "Fold 2\n",
      "[[56858     5]\n",
      " [   35    63]]\n",
      "Fold 3\n",
      "[[56856     7]\n",
      " [   38    60]]\n",
      "Fold 4\n",
      "[[56852    11]\n",
      " [   40    58]]\n",
      "Final Confusion Matrix\n",
      "[[5.68552e+04 7.80000e+00]\n",
      " [4.00000e+01 5.84000e+01]]\n",
      "F1 score: 0.709599027946537\n",
      "Recall: 0.5934959349593495\n",
      "Precision: 0.8821752265861027\n",
      "Checking class weight None and coefficient 0.046415888336127774\n",
      "Fold 0\n",
      "[[56850    13]\n",
      " [   45    54]]\n",
      "Fold 1\n",
      "[[56860     3]\n",
      " [   39    60]]\n",
      "Fold 2\n",
      "[[56858     5]\n",
      " [   34    64]]\n",
      "Fold 3\n",
      "[[56856     7]\n",
      " [   37    61]]\n",
      "Fold 4\n",
      "[[56852    11]\n",
      " [   39    59]]\n",
      "Final Confusion Matrix\n",
      "[[5.68552e+04 7.80000e+00]\n",
      " [3.88000e+01 5.96000e+01]]\n",
      "F1 score: 0.7189384800965019\n",
      "Recall: 0.6056910569105691\n",
      "Precision: 0.884272997032641\n",
      "Checking class weight None and coefficient 0.0774263682681127\n",
      "Fold 0\n",
      "[[56850    13]\n",
      " [   45    54]]\n",
      "Fold 1\n",
      "[[56860     3]\n",
      " [   39    60]]\n",
      "Fold 2\n",
      "[[56858     5]\n",
      " [   32    66]]\n",
      "Fold 3\n",
      "[[56855     8]\n",
      " [   37    61]]\n",
      "Fold 4\n",
      "[[56852    11]\n",
      " [   40    58]]\n",
      "Final Confusion Matrix\n",
      "[[5.6855e+04 8.0000e+00]\n",
      " [3.8600e+01 5.9800e+01]]\n",
      "F1 score: 0.7196149217809867\n",
      "Recall: 0.6077235772357723\n",
      "Precision: 0.8820058997050148\n",
      "Checking class weight None and coefficient 0.1291549665014884\n",
      "Fold 0\n",
      "[[56852    11]\n",
      " [   45    54]]\n",
      "Fold 1\n",
      "[[56860     3]\n",
      " [   39    60]]\n",
      "Fold 2\n",
      "[[56857     6]\n",
      " [   31    67]]\n",
      "Fold 3\n",
      "[[56854     9]\n",
      " [   36    62]]\n",
      "Fold 4\n",
      "[[56852    11]\n",
      " [   40    58]]\n",
      "Final Confusion Matrix\n",
      "[[5.6855e+04 8.0000e+00]\n",
      " [3.8200e+01 6.0200e+01]]\n",
      "F1 score: 0.7226890756302521\n",
      "Recall: 0.6117886178861789\n",
      "Precision: 0.8826979472140762\n",
      "Checking class weight None and coefficient 0.21544346900318834\n",
      "Fold 0\n",
      "[[56852    11]\n",
      " [   44    55]]\n",
      "Fold 1\n",
      "[[56860     3]\n",
      " [   39    60]]\n",
      "Fold 2\n",
      "[[56857     6]\n",
      " [   31    67]]\n",
      "Fold 3\n",
      "[[56853    10]\n",
      " [   38    60]]\n",
      "Fold 4\n",
      "[[56851    12]\n",
      " [   39    59]]\n",
      "Final Confusion Matrix\n",
      "[[5.68546e+04 8.40000e+00]\n",
      " [3.82000e+01 6.02000e+01]]\n",
      "F1 score: 0.7209580838323354\n",
      "Recall: 0.6117886178861789\n",
      "Precision: 0.8775510204081632\n",
      "Checking class weight None and coefficient 0.3593813663804626\n",
      "Fold 0\n",
      "[[56852    11]\n",
      " [   44    55]]\n",
      "Fold 1\n",
      "[[56860     3]\n",
      " [   39    60]]\n",
      "Fold 2\n",
      "[[56857     6]\n",
      " [   29    69]]\n",
      "Fold 3\n",
      "[[56853    10]\n",
      " [   38    60]]\n",
      "Fold 4\n",
      "[[56850    13]\n",
      " [   39    59]]\n",
      "Final Confusion Matrix\n",
      "[[5.68544e+04 8.60000e+00]\n",
      " [3.78000e+01 6.06000e+01]]\n",
      "F1 score: 0.7231503579952268\n",
      "Recall: 0.6158536585365854\n",
      "Precision: 0.8757225433526011\n",
      "Checking class weight None and coefficient 0.5994842503189409\n",
      "Fold 0\n",
      "[[56852    11]\n",
      " [   43    56]]\n",
      "Fold 1\n",
      "[[56860     3]\n",
      " [   38    61]]\n",
      "Fold 2\n",
      "[[56857     6]\n",
      " [   29    69]]\n",
      "Fold 3\n",
      "[[56853    10]\n",
      " [   39    59]]\n",
      "Fold 4\n",
      "[[56850    13]\n",
      " [   39    59]]\n",
      "Final Confusion Matrix\n",
      "[[5.68544e+04 8.60000e+00]\n",
      " [3.76000e+01 6.08000e+01]]\n",
      "F1 score: 0.7246722288438616\n",
      "Recall: 0.6178861788617885\n",
      "Precision: 0.8760806916426513\n",
      "Checking class weight None and coefficient 1.0\n",
      "Fold 0\n",
      "[[56852    11]\n",
      " [   43    56]]\n",
      "Fold 1\n",
      "[[56860     3]\n",
      " [   38    61]]\n",
      "Fold 2\n",
      "[[56857     6]\n",
      " [   29    69]]\n",
      "Fold 3\n",
      "[[56853    10]\n",
      " [   39    59]]\n",
      "Fold 4\n",
      "[[56850    13]\n",
      " [   39    59]]\n",
      "Final Confusion Matrix\n",
      "[[5.68544e+04 8.60000e+00]\n",
      " [3.76000e+01 6.08000e+01]]\n",
      "F1 score: 0.7246722288438616\n",
      "Recall: 0.6178861788617885\n",
      "Precision: 0.8760806916426513\n",
      "Checking class weight balanced and coefficient 0.01\n",
      "Fold 0\n",
      "[[55650  1213]\n",
      " [    8    91]]\n",
      "Fold 1\n",
      "[[55603  1260]\n",
      " [    9    90]]\n",
      "Fold 2\n",
      "[[55489  1374]\n",
      " [    8    90]]\n",
      "Fold 3\n",
      "[[55540  1323]\n",
      " [    8    90]]\n",
      "Fold 4\n",
      "[[55543  1320]\n",
      " [   11    87]]\n",
      "Final Confusion Matrix\n",
      "[[5.5565e+04 1.2980e+03]\n",
      " [8.8000e+00 8.9600e+01]]\n",
      "F1 score: 0.12059219380888292\n",
      "Recall: 0.910569105691057\n",
      "Precision: 0.06457192274430672\n",
      "Checking class weight balanced and coefficient 0.016681005372000592\n",
      "Fold 0\n",
      "[[55637  1226]\n",
      " [    8    91]]\n",
      "Fold 1\n",
      "[[55595  1268]\n",
      " [    9    90]]\n",
      "Fold 2\n",
      "[[55481  1382]\n",
      " [    8    90]]\n",
      "Fold 3\n",
      "[[55539  1324]\n",
      " [    8    90]]\n",
      "Fold 4\n",
      "[[55542  1321]\n",
      " [   11    87]]\n",
      "Final Confusion Matrix\n",
      "[[5.55588e+04 1.30420e+03]\n",
      " [8.80000e+00 8.96000e+01]]\n",
      "F1 score: 0.12009114059777509\n",
      "Recall: 0.910569105691057\n",
      "Precision: 0.06428468933849907\n",
      "Checking class weight balanced and coefficient 0.027825594022071243\n",
      "Fold 0\n",
      "[[55624  1239]\n",
      " [    8    91]]\n",
      "Fold 1\n",
      "[[55593  1270]\n",
      " [    9    90]]\n",
      "Fold 2\n",
      "[[55474  1389]\n",
      " [    8    90]]\n",
      "Fold 3\n",
      "[[55540  1323]\n",
      " [    8    90]]\n",
      "Fold 4\n",
      "[[55551  1312]\n",
      " [   11    87]]\n",
      "Final Confusion Matrix\n",
      "[[5.55564e+04 1.30660e+03]\n",
      " [8.80000e+00 8.96000e+01]]\n",
      "F1 score: 0.1198983005486418\n",
      "Recall: 0.910569105691057\n",
      "Precision: 0.06417418707921502\n",
      "Checking class weight balanced and coefficient 0.046415888336127774\n",
      "Fold 0\n",
      "[[55621  1242]\n",
      " [    8    91]]\n",
      "Fold 1\n",
      "[[55586  1277]\n",
      " [    9    90]]\n",
      "Fold 2\n",
      "[[55465  1398]\n",
      " [    8    90]]\n",
      "Fold 3\n",
      "[[55541  1322]\n",
      " [    8    90]]\n",
      "Fold 4\n",
      "[[55548  1315]\n",
      " [   11    87]]\n",
      "Final Confusion Matrix\n",
      "[[5.55522e+04 1.31080e+03]\n",
      " [8.80000e+00 8.96000e+01]]\n",
      "F1 score: 0.11956231651988257\n",
      "Recall: 0.910569105691057\n",
      "Precision: 0.0639817195087118\n",
      "Checking class weight balanced and coefficient 0.0774263682681127\n",
      "Fold 0\n",
      "[[55617  1246]\n",
      " [    8    91]]\n",
      "Fold 1\n",
      "[[55584  1279]\n",
      " [    9    90]]\n",
      "Fold 2\n",
      "[[55461  1402]\n",
      " [    8    90]]\n",
      "Fold 3\n",
      "[[55538  1325]\n",
      " [    8    90]]\n",
      "Fold 4\n",
      "[[55540  1323]\n",
      " [   11    87]]\n",
      "Final Confusion Matrix\n",
      "[[5.5548e+04 1.3150e+03]\n",
      " [8.8000e+00 8.9600e+01]]\n",
      "F1 score: 0.11922821024617433\n",
      "Recall: 0.910569105691057\n",
      "Precision: 0.06379040296169729\n",
      "Checking class weight balanced and coefficient 0.1291549665014884\n",
      "Fold 0\n",
      "[[55613  1250]\n",
      " [    8    91]]\n",
      "Fold 1\n",
      "[[55584  1279]\n",
      " [    9    90]]\n",
      "Fold 2\n",
      "[[55455  1408]\n",
      " [    8    90]]\n",
      "Fold 3\n",
      "[[55540  1323]\n",
      " [    8    90]]\n",
      "Fold 4\n",
      "[[55535  1328]\n",
      " [   11    87]]\n",
      "Final Confusion Matrix\n",
      "[[5.55454e+04 1.31760e+03]\n",
      " [8.80000e+00 8.96000e+01]]\n",
      "F1 score: 0.11902231668437832\n",
      "Recall: 0.910569105691057\n",
      "Precision: 0.06367254121660035\n",
      "Checking class weight balanced and coefficient 0.21544346900318834\n"
     ]
    }
   ],
   "source": [
    "weights = [None,'balanced']\n",
    "coefficients = np.logspace(-2,0,10)\n",
    "fscore = []\n",
    "recall = []\n",
    "precision = []\n",
    "param_permuations = list(itertools.product(weights, coefficients))\n",
    "for cw,C in param_permuations:\n",
    "    print('Checking class weight {} and coefficient {}'.format(cw, C))\n",
    "    cf = train_logistic_regression(data_sc, cw, C)\n",
    "    TP = cf[1][1]\n",
    "    FP = cf[0][1]\n",
    "    FN = cf[1][0]\n",
    "    prec = TP/(TP+FP)\n",
    "    rec = TP/(TP+FN)\n",
    "    f1 = prec*rec*2/(prec+rec)\n",
    "    print('F1 score:', f1)\n",
    "    print('Recall:', rec)\n",
    "    print('Precision:', prec)\n",
    "    fscore.append(f1)\n",
    "    recall.append(rec)\n",
    "    precision.append(prec)\n",
    "\n",
    "idx = np.argmax(recall)\n",
    "best_params = param_permuations[idx]\n",
    "print('Best parameters found for Logistic Regression is {} class weights and {} coefficient'.format(best_params[0], best_params[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We see that as we improve fraud accuracy, valid accuracy decreases and vice versa. For the best fraud precision, the results suggest that we utilize the scaled data, balanced class weights and a strong regularization (small C coefficient)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
